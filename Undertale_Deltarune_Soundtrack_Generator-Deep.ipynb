{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undertale & Deltarune Soundtrack Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [**Table of Contents**](#Table-of-Contents)\n",
    "\n",
    "1. [**Imports**](#Imports)\n",
    "\n",
    "2. [**Data Processing**](#Data-Processing)\n",
    "\n",
    "    2.1 [Data Loading](#Data-Loading)\n",
    "    \n",
    "    2.2 [Data Preprocessing](#Data-Preprocessing)\n",
    "    \n",
    "    2.3 [Dataset & Dataloader Definition](#Dataset-&-Dataloader-Definition)\n",
    "    \n",
    "3. [**Model Definition**](#Model-Definition)\n",
    "    \n",
    "4. [**Hyperparameters & Instantiation**](#Hyperparameters-&-Instantiation)\n",
    "\n",
    "5. [**Training**](#Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T11:45:54.197252Z",
     "start_time": "2019-08-05T11:45:53.594319Z"
    }
   },
   "outputs": [],
   "source": [
    "import os                                         # File handling\n",
    "import itertools                                  # chain() for merging lists\n",
    "import random                                     # Shuffling\n",
    "import collections                                # Useful tools like Counter, OrderedDict\n",
    "import math                                       # For... math\n",
    "from decimal import Decimal                       # Scientific notations in string formatting\n",
    "from time import time                             # For use in progress bar\n",
    "\n",
    "import tqdm.auto as tqdm                          # Progress bar\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch                                      # Deep Learning Framework\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt                   # Plotting training progress\n",
    "from matplotlib.ticker import AutoLocator\n",
    "%matplotlib inline\n",
    "\n",
    "fig_bg_color = \"lightsteelblue\"\n",
    "plot_bg_color = \"slategray\"\n",
    "fontsize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T06:55:43.051798Z",
     "start_time": "2019-03-17T06:55:43.046023Z"
    }
   },
   "source": [
    "## Data Processing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Read the text files in the target directory.\n",
    "\n",
    "Do some processing to make sure the texts are clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T11:45:54.271074Z",
     "start_time": "2019-08-05T11:45:54.199245Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANOTHER_HIM_-_DeltaRune.txt', '42 46 49 53 0 42 46 '),\n",
       " ('A_Town_Called_Hometown_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '73 89 0 73 89 0 73 8'),\n",
       " ('Basement_Deltarune_-_Arranged_for_Piano.txt', '39 51 0 39 51 0 39 5'),\n",
       " ('Before_the_Story_Deltarune_-_Arranged_for_piano_.txt',\n",
       "  '48 0 48 0 48 0 48 0 '),\n",
       " ('Card_Castle_Deltarune_-_Arranged_for_Piano.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Checker_Dance_Deltarune_-_Arranged_for_Piano.txt', '30 0 30 0 30 0 30 0 '),\n",
       " ('Deltarune_-_Beginning.txt', '48 55 0 48 55 0 48 5'),\n",
       " ('Deltarune_-_Chaos_King.txt', '27 39 0 27 39 0 27 3'),\n",
       " ('Deltarune_-_Darkness_Falls.txt', '61 64 71 75 0 61 64 '),\n",
       " ('Deltarune_-_Dont_Forget_Ending_Theme_Solo_Piano_Version.txt',\n",
       "  '77 0 77 0 77 0 77 0 '),\n",
       " ('Deltarune_-_Friendship.txt', '74 0 74 0 74 0 74 0 '),\n",
       " ('Deltarune_-_Gallery.txt', '32 36 39 68 0 32 36 '),\n",
       " ('Deltarune_-_Lancer_Battle.txt', '62 0 62 0 62 0 0 0 0'),\n",
       " ('DELTARUNE_-_Lancer_piano_solo.txt', '0 0 0 62 0 62 0 62 0'),\n",
       " ('Deltarune_-_Lantern.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Deltarune_-_Rude_Buster_Playable.txt', '31 43 0 31 43 0 31 4'),\n",
       " ('Deltarune_-_The_Chase.txt', '24 31 0 24 31 0 24 3'),\n",
       " ('Deltarune_-_THE_WORLD_REVOLVING.txt', '45 57 0 45 57 0 45 5'),\n",
       " ('Deltarune_-_Thrash_Machine.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Deltarune_-_You_Can_Always_Come_Home.txt', '46 0 46 0 46 0 46 0 '),\n",
       " ('Deltarune_Legend.txt', '0 0 0 0 0 0 0 0 0 0 '),\n",
       " ('Empty_Town_Deltarune_-_Arranged_for_Piano.txt', '58 70 0 58 70 0 58 7'),\n",
       " ('Fanfare_Deltarune_-_Arranged_for_Piano.txt', '37 49 0 37 49 0 37 4'),\n",
       " ('Hip_Shop_Deltarune_-_Arranged_for_Piano.txt', '44 68 0 44 68 0 44 6'),\n",
       " ('Im_Very_Bad_Deltarune_-_Arranged_for_Piano.txt', '67 0 67 0 67 0 67 0 '),\n",
       " ('Man_Deltarune.txt', '61 0 61 0 61 0 61 0 '),\n",
       " ('Quiet_Autumn_Deltarune_-_Arranged_for_Piano.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Rouxls_Kaard.txt', '43 74 0 43 74 0 43 7'),\n",
       " ('Scarlet_Forest_-_Deltarune_Advanced_Piano.txt', '55 0 55 0 55 0 55 0 '),\n",
       " ('School_-_DeltaRune.txt', '38 66 0 38 66 0 38 6'),\n",
       " ('Susie_Deltarune_-_Arranged_for_Piano.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('The_Circus_Deltarune_-_Arranged_for_Piano.txt', '54 0 54 0 54 0 54 0 '),\n",
       " ('The_Door_Deltarune_-_Arranged_for_Piano.txt', '49 80 0 49 80 0 49 8'),\n",
       " ('The_Field_of_Hopes_and_Dreams_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '56 68 71 78 0 56 68 '),\n",
       " ('THE_HOLY_Deltarune_-_Arranged_for_Piano.txt', '39 61 65 0 39 61 65 '),\n",
       " ('Undertale_-_004_Fallen_Down__085_Fallen_Down_Reprise.txt',\n",
       "  '63 79 0 63 79 0 63 7'),\n",
       " ('Undertale_-_005_Ruins.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('Undertale_-_010_Ghost_Fight.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_011_Determination.txt', '40 79 0 40 79 0 40 7'),\n",
       " ('Undertale_-_031_Waterfall.txt', '65 0 65 0 65 0 65 0 '),\n",
       " ('Undertale_-_036_Dummy.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_043_Temmie_Village.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Undertale_-_046_Spear_of_Justice.txt', '32 44 68 75 80 0 32 '),\n",
       " ('Undertale_-_048_Alphys.txt', '47 0 47 0 47 0 47 0 '),\n",
       " ('Undertale_-_050_Metal_Crusher.txt', '64 0 64 0 64 0 64 0 '),\n",
       " ('Undertale_-_051_Another_Medium.txt', '85 0 85 0 85 0 85 0 '),\n",
       " ('Undertale_-_053_Stronger_Monsters.txt', '35 0 35 0 35 0 35 0 '),\n",
       " ('Undertale_-_063_Its_Raining_Somewhere_Else.txt', '49 0 49 0 49 52 0 49'),\n",
       " ('Undertale_-_065_CORE.txt', '69 72 74 0 69 72 74 '),\n",
       " ('Undertale_-_068_Death_by_Glamour.txt', '41 0 41 0 41 0 41 0 '),\n",
       " ('Undertale_-_079_Your_Best_Nightmare.txt', '35 47 58 70 0 35 47 '),\n",
       " ('Undertale_-_080_Finale.txt', '47 54 69 0 47 54 69 '),\n",
       " ('Undertale_-_100_MEGALOVANIA.txt', '63 0 63 0 63 0 63 0 '),\n",
       " ('Undertale_-_ASGORE.txt', '50 57 65 0 50 57 65 '),\n",
       " ('Undertale_-_Battle_Against_a_True_Hero.txt', '88 0 88 0 88 0 88 0 '),\n",
       " ('Undertale_-_Bonetrousle.txt', '37 0 37 0 37 0 37 0 '),\n",
       " ('Undertale_-_Heartache.txt', '31 47 0 31 47 0 31 4'),\n",
       " ('Undertale_-_Hopes_and_Dreams.txt', '64 78 0 64 78 0 64 7'),\n",
       " ('Undertale_-_Memory.txt', '77 0 77 0 77 0 77 0 '),\n",
       " ('Undertale_-_sans.txt', '33 0 33 0 33 0 33 0 '),\n",
       " ('Undertale_-_SAVE_the_World.txt', '45 57 67 0 45 57 67 '),\n",
       " ('Undertale_-_Spider_Dance.txt', '42 73 78 0 42 73 78 '),\n",
       " ('Undertale_Undertale_Piano.txt', '59 0 59 0 59 0 59 0 '),\n",
       " ('Vs._Susie_Deltarune_-_Arranged_for_Piano.txt', '47 0 47 0 47 0 47 0 ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(texts_dir):\n",
    "\n",
    "    if not os.path.isdir(texts_dir):\n",
    "        raise FileNotFoundError(\"given text directory not found: {}\".format(texts_dir))\n",
    "\n",
    "    texts = []\n",
    "    \n",
    "    for text_path in (file.path for file in os.scandir(texts_dir) if file.is_file() and file.name.endswith(\".txt\")):\n",
    "        with open(file=text_path, mode='r', encoding=\"utf-8\") as text_file:\n",
    "            \n",
    "            text = text_file.read().strip()\n",
    "\n",
    "            if not text.replace(' ', '').isdigit():\n",
    "                raise RuntimeError(\"one or more characters other than digits and white spaces are detected: {}\".format(text_path))\n",
    "\n",
    "            while \"  \" in text:\n",
    "                text = text.replace(\"  \", ' ')\n",
    "            \n",
    "            texts.append((text_path, text))\n",
    "    \n",
    "    return dict(texts)\n",
    "\n",
    "\n",
    "[(os.path.split(text_path)[1], text[:20]) for text_path, text in get_texts(\"./source/converted_texts\").items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get integers out of the text and make lists of ints.\n",
    "\n",
    "These lists can be used for the input of the models, or be further processed to compress or simplify the sequences.\n",
    "\n",
    "In this notebook, I'll leave the data as it is and do note-by-note. (Similar to Character-By-Character approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T11:45:54.696937Z",
     "start_time": "2019-08-05T11:45:54.272076Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 46, 49, 53, 0, 42, 46, 49, 53, 0], [73, 89, 0, 73, 89, 0, 73, 89, 0, 73], [39, 51, 0, 39, 51, 0, 39, 51, 0, 39], [48, 0, 48, 0, 48, 0, 48, 0, 48, 0], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [30, 0, 30, 0, 30, 0, 30, 0, 30, 0], [48, 55, 0, 48, 55, 0, 48, 55, 0, 48], [27, 39, 0, 27, 39, 0, 27, 39, 0, 27], [61, 64, 71, 75, 0, 61, 64, 71, 75, 0], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [74, 0, 74, 0, 74, 0, 74, 0, 74, 0], [32, 36, 39, 68, 0, 32, 36, 39, 68, 0], [62, 0, 62, 0, 62, 0, 0, 0, 0, 65], [0, 0, 0, 62, 0, 62, 0, 62, 0, 62], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [31, 43, 0, 31, 43, 0, 31, 43, 0, 31], [24, 31, 0, 24, 31, 0, 24, 31, 0, 24], [45, 57, 0, 45, 57, 0, 45, 57, 0, 45], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [46, 0, 46, 0, 46, 0, 46, 0, 46, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [58, 70, 0, 58, 70, 0, 58, 70, 0, 58], [37, 49, 0, 37, 49, 0, 37, 49, 0, 37], [44, 68, 0, 44, 68, 0, 44, 68, 0, 44], [67, 0, 67, 0, 67, 0, 67, 0, 67, 0], [61, 0, 61, 0, 61, 0, 61, 0, 61, 0], [49, 0, 49, 0, 49, 0, 49, 0, 54, 0], [43, 74, 0, 43, 74, 0, 43, 74, 0, 43], [55, 0, 55, 0, 55, 0, 55, 0, 55, 0], [38, 66, 0, 38, 66, 0, 38, 66, 0, 38], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [54, 0, 54, 0, 54, 0, 54, 0, 54, 0], [49, 80, 0, 49, 80, 0, 49, 80, 0, 49], [56, 68, 71, 78, 0, 56, 68, 71, 78, 0], [39, 61, 65, 0, 39, 61, 65, 0, 39, 61], [63, 79, 0, 63, 79, 0, 63, 79, 0, 63], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [40, 79, 0, 40, 79, 0, 40, 79, 0, 40], [65, 0, 65, 0, 65, 0, 65, 0, 65, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [32, 44, 68, 75, 80, 0, 32, 44, 68, 75], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0], [64, 0, 64, 0, 64, 0, 64, 0, 64, 0], [85, 0, 85, 0, 85, 0, 85, 0, 80, 0], [35, 0, 35, 0, 35, 0, 35, 0, 35, 0], [49, 0, 49, 0, 49, 52, 0, 49, 52, 56], [69, 72, 74, 0, 69, 72, 74, 0, 69, 72], [41, 0, 41, 0, 41, 0, 41, 0, 41, 0], [35, 47, 58, 70, 0, 35, 47, 58, 70, 0], [47, 54, 69, 0, 47, 54, 69, 0, 47, 54], [63, 0, 63, 0, 63, 0, 63, 0, 0, 63], [50, 57, 65, 0, 50, 57, 65, 0, 50, 57], [88, 0, 88, 0, 88, 0, 88, 0, 88, 0], [37, 0, 37, 0, 37, 0, 37, 0, 37, 0], [31, 47, 0, 31, 47, 0, 31, 47, 0, 31], [64, 78, 0, 64, 78, 0, 64, 78, 0, 64], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [33, 0, 33, 0, 33, 0, 33, 0, 33, 0], [45, 57, 67, 0, 45, 57, 67, 0, 45, 57], [42, 73, 78, 0, 42, 73, 78, 0, 73, 78], [59, 0, 59, 0, 59, 0, 59, 0, 59, 0], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0]]\n"
     ]
    }
   ],
   "source": [
    "def texts_to_intlists(text_list):\n",
    "    \n",
    "    intlists = []\n",
    "    \n",
    "    for i, text in enumerate(iterable=text_list):\n",
    "        \n",
    "        int_strings = text.split(' ')\n",
    "        \n",
    "        if not all(int_str.isdigit() for int_str in int_strings):\n",
    "            raise RuntimeError(\"non-digit string detected in text {}\".format(i))\n",
    "\n",
    "        ints = [int(int_str) for int_str in int_strings]\n",
    "        \n",
    "        intlists.append(ints)\n",
    "        \n",
    "    return intlists\n",
    "\n",
    "\n",
    "print([ints[:10] for ints in texts_to_intlists(get_texts(\"./source/converted_texts\").values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset class from which training data can be sampled.\n",
    "\n",
    "This Dataset should convert the encoded sequence above into tensors\n",
    "\n",
    "and have a method for shuffling the order of multiple sequences while\n",
    "\n",
    "leaving the patterns inside of each sequence untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T11:45:54.707941Z",
     "start_time": "2019-08-05T11:45:54.699927Z"
    }
   },
   "outputs": [],
   "source": [
    "class UndertaleDeltaruneDataset(Dataset):\n",
    "    def __init__(self, texts_dir, batch_size=1):\n",
    "        self.texts = get_texts(texts_dir) # read and get a dictionary of {file_paths: text_contents}\n",
    "        self.sequences = texts_to_intlists(self.texts.values())\n",
    "\n",
    "        self.texts_dir = texts_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def data_len(self):\n",
    "        return sum([len(sequence) for sequence in self.sequences])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        shuffled_list = list(itertools.chain(*random.sample(self.sequences, len(self.sequences))))\n",
    "        inputs = torch.LongTensor(shuffled_list[:-1])\n",
    "        labels = torch.LongTensor(shuffled_list[1:])\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom class that loads the data from the dataset above and\n",
    "\n",
    "allows iteration over the dataset, yielding a small sequence batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T11:45:50.096Z"
    }
   },
   "outputs": [],
   "source": [
    "class UDBatchLoader:\n",
    "    def __init__(self, ud_dataset, batch_size, sequence_len, drop_last=False, batch_first=True):\n",
    "        self.ud_dataset = ud_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.drop_last = drop_last\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return math.floor((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "        return math.ceil((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "    \n",
    "    def generator(self):\n",
    "        seq_len = self.sequence_len\n",
    "        n_seq_batches = self.__len__()\n",
    "        batch_first = self.batch_first\n",
    "        \n",
    "        input_batch, target_batch = next(iter(DataLoader(self.ud_dataset, self.batch_size)))\n",
    "        if not batch_first:\n",
    "            input_batch = input_batch.transpose(0, 1).contiguous()\n",
    "            target_batch = target_batch.transpose(0, 1).contiguous()\n",
    "        \n",
    "        for start, end in zip(range(0, seq_len * n_seq_batches, seq_len), range(seq_len, (seq_len + 1) * n_seq_batches, seq_len)):\n",
    "            if batch_first:\n",
    "                yield (input_batch[:, start:end].contiguous(), target_batch[:, start:end].contiguous())\n",
    "            else:\n",
    "                yield (input_batch[start:end], target_batch[start:end])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Define the model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T11:45:50.502Z"
    }
   },
   "outputs": [],
   "source": [
    "class UDNet(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout):\n",
    "        super(UDNet, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.init_hiddens = nn.Parameter(torch.randn(num_layers, 1, hidden_size))\n",
    "        self.init_cells   = nn.Parameter(torch.randn(num_layers, 1, hidden_size))\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=129, embedding_dim=hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=hidden_size, out_features=256)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=256, out_features=512)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=512, out_features=129)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hiddens=None):\n",
    "        if hiddens is None:\n",
    "            hiddens = self.get_init_hiddens(x.size(0))\n",
    "\n",
    "        x = self.embed(x)\n",
    "\n",
    "        x, new_hiddens = self.lstm(x, hiddens)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, new_hiddens\n",
    "\n",
    "    def get_init_hiddens(self, n_batches):\n",
    "        return [self.init_hiddens.repeat(1, n_batches, 1), self.init_cells.repeat(1, n_batches, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T11:45:51.094Z"
    }
   },
   "outputs": [],
   "source": [
    "def free_running_generation(generator, inputs, seq_len):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    generator (Generator): the generator model.\n",
    "    inputs (LongTensor): 2D tensor with dimensions [n_batches, 1].\n",
    "                         If the given dimensions are [n_batches, seq_len],\n",
    "                         then only the first timestep is used.\n",
    "    seq_len (int): length of sequence to generate.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    output_sequence (LongTensor): tensor of generated outputs.\n",
    "    hiddens (list[Tensor]): updated hidden states.\n",
    "    \"\"\"\n",
    "    output_sequence = []\n",
    "    if return_all_hiddens:\n",
    "        internal_hiddens = []\n",
    "\n",
    "    hiddens = generator.get_init_hiddens(inputs.size(0))\n",
    "    x = inputs[:, :1]\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        y, hiddens = generator(x, hiddens, return_all_hiddens=False)\n",
    "        y = torch.multinomial(y.squeeze(1).softmax(dim=-1), num_samples=1)\n",
    "        output_sequence.append(y)\n",
    "        x = y\n",
    "    output_sequence = torch.cat(output_sequence, dim=1)\n",
    "\n",
    "    return output_sequence, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T11:45:51.265Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Sequence Total Length: 893324\n",
      "\n",
      "UDNet(\n",
      "  (embed): Embedding(129, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=10, batch_first=True, dropout=0.2)\n",
      "  (fc0): Sequential(\n",
      "    (0): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Dropout(p=0.2)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=512, out_features=129, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "seed                   = 0\n",
    "batch_size             = 4\n",
    "sequence_length        = 12800\n",
    "\n",
    "n_logs                 = 30\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "ud_dataset = UndertaleDeltaruneDataset(\"./source/converted_texts\", batch_size)\n",
    "ud_loader = UDBatchLoader(ud_dataset, batch_size, sequence_length, drop_last=True, batch_first=True)\n",
    "\n",
    "model = UDNet(hidden_size=256, num_layers=10, dropout=0.2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "print()\n",
    "print('Data Sequence Total Length:', ud_dataset.data_len())\n",
    "print()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T11:45:51.961Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.410981\n",
      "Average Top-1 Accuracy: 0.900944\n",
      "Average Top-5 Accuracy: 0.972756\n",
      "===============================================\n",
      "\n",
      "Epoch 77 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.409148\n",
      "Average Top-1 Accuracy: 0.901425\n",
      "Average Top-5 Accuracy: 0.972948\n",
      "===============================================\n",
      "\n",
      "Epoch 78 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.408127\n",
      "Average Top-1 Accuracy: 0.901641\n",
      "Average Top-5 Accuracy: 0.973089\n",
      "===============================================\n",
      "\n",
      "Epoch 79 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.407110\n",
      "Average Top-1 Accuracy: 0.901728\n",
      "Average Top-5 Accuracy: 0.973266\n",
      "===============================================\n",
      "\n",
      "Epoch 80 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.404146\n",
      "Average Top-1 Accuracy: 0.902516\n",
      "Average Top-5 Accuracy: 0.973523\n",
      "===============================================\n",
      "\n",
      "Epoch 81 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.404962\n",
      "Average Top-1 Accuracy: 0.902107\n",
      "Average Top-5 Accuracy: 0.973498\n",
      "===============================================\n",
      "\n",
      "Epoch 82 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.404567\n",
      "Average Top-1 Accuracy: 0.902197\n",
      "Average Top-5 Accuracy: 0.973481\n",
      "===============================================\n",
      "\n",
      "Epoch 83 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.401844\n",
      "Average Top-1 Accuracy: 0.902748\n",
      "Average Top-5 Accuracy: 0.973841\n",
      "===============================================\n",
      "\n",
      "Epoch 84 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.402269\n",
      "Average Top-1 Accuracy: 0.902492\n",
      "Average Top-5 Accuracy: 0.973865\n",
      "===============================================\n",
      "\n",
      "Epoch 85 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.399839\n",
      "Average Top-1 Accuracy: 0.903099\n",
      "Average Top-5 Accuracy: 0.973952\n",
      "===============================================\n",
      "\n",
      "Epoch 86 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.397910\n",
      "Average Top-1 Accuracy: 0.903578\n",
      "Average Top-5 Accuracy: 0.974220\n",
      "===============================================\n",
      "\n",
      "Epoch 87 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.397705\n",
      "Average Top-1 Accuracy: 0.903402\n",
      "Average Top-5 Accuracy: 0.974321\n",
      "===============================================\n",
      "\n",
      "Epoch 88 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.396538\n",
      "Average Top-1 Accuracy: 0.903536\n",
      "Average Top-5 Accuracy: 0.974328\n",
      "===============================================\n",
      "\n",
      "Epoch 89 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.397975\n",
      "Average Top-1 Accuracy: 0.903207\n",
      "Average Top-5 Accuracy: 0.974413\n",
      "===============================================\n",
      "\n",
      "Epoch 90 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.394176\n",
      "Average Top-1 Accuracy: 0.903995\n",
      "Average Top-5 Accuracy: 0.974805\n",
      "===============================================\n",
      "\n",
      "Epoch 91 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.393458\n",
      "Average Top-1 Accuracy: 0.904108\n",
      "Average Top-5 Accuracy: 0.974736\n",
      "===============================================\n",
      "\n",
      "Epoch 92 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.392788\n",
      "Average Top-1 Accuracy: 0.904109\n",
      "Average Top-5 Accuracy: 0.974903\n",
      "===============================================\n",
      "\n",
      "Epoch 93 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.390855\n",
      "Average Top-1 Accuracy: 0.904483\n",
      "Average Top-5 Accuracy: 0.975002\n",
      "===============================================\n",
      "\n",
      "Epoch 94 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.389556\n",
      "Average Top-1 Accuracy: 0.904687\n",
      "Average Top-5 Accuracy: 0.975207\n",
      "===============================================\n",
      "\n",
      "Epoch 95 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.388081\n",
      "Average Top-1 Accuracy: 0.904923\n",
      "Average Top-5 Accuracy: 0.975321\n",
      "===============================================\n",
      "\n",
      "Epoch 96 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.387615\n",
      "Average Top-1 Accuracy: 0.905022\n",
      "Average Top-5 Accuracy: 0.975377\n",
      "===============================================\n",
      "\n",
      "Epoch 97 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.386224\n",
      "Average Top-1 Accuracy: 0.905077\n",
      "Average Top-5 Accuracy: 0.975580\n",
      "===============================================\n",
      "\n",
      "Epoch 98 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.384949\n",
      "Average Top-1 Accuracy: 0.905357\n",
      "Average Top-5 Accuracy: 0.975698\n",
      "===============================================\n",
      "\n",
      "Epoch 99 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.384414\n",
      "Average Top-1 Accuracy: 0.905491\n",
      "Average Top-5 Accuracy: 0.975816\n",
      "===============================================\n",
      "\n",
      "Epoch 100 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.383514\n",
      "Average Top-1 Accuracy: 0.905641\n",
      "Average Top-5 Accuracy: 0.976009\n",
      "===============================================\n",
      "\n",
      "Epoch 101 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.381064\n",
      "Average Top-1 Accuracy: 0.906231\n",
      "Average Top-5 Accuracy: 0.976125\n",
      "===============================================\n",
      "\n",
      "Epoch 102 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.378635\n",
      "Average Top-1 Accuracy: 0.906587\n",
      "Average Top-5 Accuracy: 0.976460\n",
      "===============================================\n",
      "\n",
      "Epoch 103 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.378261\n",
      "Average Top-1 Accuracy: 0.906756\n",
      "Average Top-5 Accuracy: 0.976505\n",
      "===============================================\n",
      "\n",
      "Epoch 104 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.378821\n",
      "Average Top-1 Accuracy: 0.906285\n",
      "Average Top-5 Accuracy: 0.976512\n",
      "===============================================\n",
      "\n",
      "Epoch 105 - LR=1.000000e-04\n",
      "===============================================\n",
      "Average Loss: 0.377213\n",
      "Average Top-1 Accuracy: 0.906566\n",
      "Average Top-5 Accuracy: 0.976684\n",
      "===============================================\n",
      "\n",
      "28/68\r"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "logs = {'epoch': [], 'lr':[], 'loss_avg': [], 'acc_1': [], 'acc_5': []}\n",
    "i_epoch = 0\n",
    "while True:\n",
    "    \n",
    "    hiddens = model.get_init_hiddens(batch_size)\n",
    "\n",
    "    running_loss = 0\n",
    "    n_top1_corrects = 0\n",
    "    n_top5_corrects = 0\n",
    "    n_instances = 0\n",
    "    for i, (inputs, labels) in enumerate(ud_loader):\n",
    "        print(\"{:d}/{:d}\".format(i, len(ud_loader)-1), end='\\r')\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.view(-1).to(device)\n",
    "\n",
    "        outputs, hidden_states = model(inputs, hiddens)\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "\n",
    "        hiddens = [hiddens[0].detach(), hiddens[1].detach()]\n",
    "\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_instances     += labels.size(0)\n",
    "        running_loss    += loss.item() * labels.size(0)\n",
    "        top5_match       = outputs.data.topk(k=5, dim=1)[1].eq(labels.unsqueeze(1))\n",
    "        n_top1_corrects += top5_match[:, 0].sum().item()\n",
    "        n_top5_corrects += top5_match.sum().item()\n",
    "        del top5_match\n",
    "\n",
    "    loss_avg = running_loss / n_instances\n",
    "    acc_1    = n_top1_corrects / n_instances\n",
    "    acc_5    = n_top5_corrects / n_instances\n",
    "\n",
    "    logs['epoch'].append(i_epoch)\n",
    "    logs['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    logs['loss_avg'].append(loss_avg)\n",
    "    logs['acc_1'].append(acc_1)\n",
    "    logs['acc_5'].append(acc_5)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print('\\n\\n'.join([\"Epoch {:d} - LR={:e}\\n===============================================\\n\".format(i_e, lr)\n",
    "                       + \"Average Loss: {:f}\\nAverage Top-1 Accuracy: {:f}\\nAverage Top-5 Accuracy: {:f}\\n\".format(l_a, a_1, a_5)\n",
    "                       + \"===============================================\"\n",
    "                       for i_e, lr, l_a, a_1, a_5 in list(zip(*list(logs.values())))[-n_logs:]]), end='\\n\\n')\n",
    "\n",
    "    if (i_epoch + 1) % 10 == 0:\n",
    "        torch.save({'logs': logs, 'state_dict': model.state_dict(), 'optim_dict': optimizer.state_dict(), 'lr_dict': lr_scheduler.state_dict()},\n",
    "                   \"deep/{:d}.pth\".format(i_epoch))\n",
    "\n",
    "    lr_scheduler.step(loss_avg)\n",
    "    i_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T14:04:25.183522Z",
     "start_time": "2019-07-31T14:04:25.055841Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save({'g': generator.state_dict(), 'd': discriminator.state_dict()}, 'professor_forcing_temp/GD_8500.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T14:08:12.637099Z",
     "start_time": "2019-07-31T14:04:50.079706Z"
    }
   },
   "outputs": [],
   "source": [
    "# generated_sequence = free_running_generation(generator, inputs[:1], 50000, return_all_hiddens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T14:10:06.985002Z",
     "start_time": "2019-07-31T14:10:06.974997Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(generated_sequence[0].cpu().numpy(), \"professor_forcing_temp/generated_sequence.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
