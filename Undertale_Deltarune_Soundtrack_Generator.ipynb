{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undertale & Deltarune Soundtrack Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. [**Table of Contents**](#Table-of-Contents)\n",
    "\n",
    "1. [**Imports**](#Imports)\n",
    "\n",
    "2. [**Data Processing**](#Data-Processing)\n",
    "\n",
    "    2.1 [Data Loading](#Data-Loading)\n",
    "    \n",
    "    2.2 [Data Preprocessing](#Data-Preprocessing)\n",
    "    \n",
    "    2.3 [Dataset Definition](#Dataset-Definition)\n",
    "    \n",
    "3. [**Model Definition**](#Model-Definition)\n",
    "    \n",
    "4. [**Hyperparameters & Instantiation**](#Hyperparameters-&-Instantiation)\n",
    "\n",
    "5. [**Training**](#Training)\n",
    "    \n",
    "    4.1 [Training Function](#Training-Function)\n",
    "    \n",
    "    4.2 [Training Session](#Training-Session)\n",
    "\n",
    "6. [**Saving Trained Model**](#Saving-Trained-Model)\n",
    "\n",
    "7. [**Generation**](#Generation)\n",
    "\n",
    "    6.1 [Generation Function](#Generation-Function)\n",
    "    \n",
    "    6.2 [Sampling Function](#Sampling-Function)\n",
    "    \n",
    "    6.3 [Music Generation](#Music-Generation)\n",
    "\n",
    "8. [**Final Summary, Notes, and Thoughts**](#Final-Summary,-Notes,-and-Thoughts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Import required packages:\n",
    "\n",
    "    * os (for file handling)\n",
    "    \n",
    "    * itertools (chain() for merging lists)\n",
    "    \n",
    "    * collections (useful tools like Counter, OrderedDict)\n",
    "    \n",
    "    * random (for sequence shuffling)\n",
    "    \n",
    "    * tqdm (progress bar)\n",
    "\n",
    "    * PyTorch (Deep Learning Framework)\n",
    "    \n",
    "    * Matplotlib (Plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T00:45:52.765897Z",
     "start_time": "2019-03-16T00:45:51.386018Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Processing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Read the text files in the target directory.\n",
    "\n",
    "Do some processing to make sure the texts are clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T00:45:54.956910Z",
     "start_time": "2019-03-16T00:45:53.858902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANOTHER_HIM_-_DeltaRune.txt', '42 46 49 53 0 42 46 '),\n",
       " ('A_Town_Called_Hometown_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '73 89 0 73 89 0 73 8'),\n",
       " ('Basement_Deltarune_-_Arranged_for_Piano.txt', '39 51 0 39 51 0 39 5'),\n",
       " ('Before_the_Story_Deltarune_-_Arranged_for_piano_.txt',\n",
       "  '48 0 48 0 48 0 48 0 '),\n",
       " ('Card_Castle_Deltarune_-_Arranged_for_Piano.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Checker_Dance_Deltarune_-_Arranged_for_Piano.txt', '30 0 30 0 30 0 30 0 '),\n",
       " ('Deltarune_-_Beginning.txt', '48 55 0 48 55 0 48 5'),\n",
       " ('Deltarune_-_Chaos_King.txt', '27 39 0 27 39 0 27 3'),\n",
       " ('Deltarune_-_Darkness_Falls.txt', '61 64 71 75 0 61 64 '),\n",
       " ('Deltarune_-_Dont_Forget_Ending_Theme_Solo_Piano_Version.txt',\n",
       "  '77 0 77 0 77 0 77 0 '),\n",
       " ('Deltarune_-_Friendship.txt', '74 0 74 0 74 0 74 0 '),\n",
       " ('Deltarune_-_Gallery.txt', '32 36 39 68 0 32 36 '),\n",
       " ('Deltarune_-_Lancer_Battle.txt', '62 0 62 0 62 0 0 0 0'),\n",
       " ('DELTARUNE_-_Lancer_piano_solo.txt', '0 0 0 62 0 62 0 62 0'),\n",
       " ('Deltarune_-_Lantern.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Deltarune_-_Rude_Buster_Playable.txt', '31 43 0 31 43 0 31 4'),\n",
       " ('Deltarune_-_The_Chase.txt', '24 31 0 24 31 0 24 3'),\n",
       " ('Deltarune_-_THE_WORLD_REVOLVING.txt', '45 57 0 45 57 0 45 5'),\n",
       " ('Deltarune_-_Thrash_Machine.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Deltarune_-_You_Can_Always_Come_Home.txt', '46 0 46 0 46 0 46 0 '),\n",
       " ('Deltarune_Legend.txt', '0 0 0 0 0 0 0 0 0 0 '),\n",
       " ('Empty_Town_Deltarune_-_Arranged_for_Piano.txt', '58 70 0 58 70 0 58 7'),\n",
       " ('Fanfare_Deltarune_-_Arranged_for_Piano.txt', '37 49 0 37 49 0 37 4'),\n",
       " ('Hip_Shop_Deltarune_-_Arranged_for_Piano.txt', '44 68 0 44 68 0 44 6'),\n",
       " ('Im_Very_Bad_Deltarune_-_Arranged_for_Piano.txt', '67 0 67 0 67 0 67 0 '),\n",
       " ('Man_Deltarune.txt', '61 0 61 0 61 0 61 0 '),\n",
       " ('Quiet_Autumn_Deltarune_-_Arranged_for_Piano.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Rouxls_Kaard.txt', '43 74 0 43 74 0 43 7'),\n",
       " ('Scarlet_Forest_-_Deltarune_Advanced_Piano.txt', '55 0 55 0 55 0 55 0 '),\n",
       " ('School_-_DeltaRune.txt', '38 66 0 38 66 0 38 6'),\n",
       " ('Susie_Deltarune_-_Arranged_for_Piano.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('The_Circus_Deltarune_-_Arranged_for_Piano.txt', '54 0 54 0 54 0 54 0 '),\n",
       " ('The_Door_Deltarune_-_Arranged_for_Piano.txt', '49 80 0 49 80 0 49 8'),\n",
       " ('The_Field_of_Hopes_and_Dreams_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '56 68 71 78 0 56 68 '),\n",
       " ('THE_HOLY_Deltarune_-_Arranged_for_Piano.txt', '39 61 65 0 39 61 65 '),\n",
       " ('Undertale_-_004_Fallen_Down__085_Fallen_Down_Reprise.txt',\n",
       "  '63 79 0 63 79 0 63 7'),\n",
       " ('Undertale_-_005_Ruins.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('Undertale_-_010_Ghost_Fight.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_011_Determination.txt', '40 79 0 40 79 0 40 7'),\n",
       " ('Undertale_-_031_Waterfall.txt', '65 0 65 0 65 0 65 0 '),\n",
       " ('Undertale_-_036_Dummy.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_043_Temmie_Village.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Undertale_-_046_Spear_of_Justice.txt', '32 44 68 75 80 0 32 '),\n",
       " ('Undertale_-_048_Alphys.txt', '47 0 47 0 47 0 47 0 '),\n",
       " ('Undertale_-_050_Metal_Crusher.txt', '64 0 64 0 64 0 64 0 '),\n",
       " ('Undertale_-_051_Another_Medium.txt', '85 0 85 0 85 0 85 0 '),\n",
       " ('Undertale_-_053_Stronger_Monsters.txt', '35 0 35 0 35 0 35 0 '),\n",
       " ('Undertale_-_063_Its_Raining_Somewhere_Else.txt', '49 0 49 0 49 52 0 49'),\n",
       " ('Undertale_-_065_CORE.txt', '69 72 74 0 69 72 74 '),\n",
       " ('Undertale_-_068_Death_by_Glamour.txt', '41 0 41 0 41 0 41 0 '),\n",
       " ('Undertale_-_079_Your_Best_Nightmare.txt', '35 47 58 70 0 35 47 '),\n",
       " ('Undertale_-_080_Finale.txt', '47 54 69 0 47 54 69 '),\n",
       " ('Undertale_-_100_MEGALOVANIA.txt', '63 0 63 0 63 0 63 0 '),\n",
       " ('Undertale_-_ASGORE.txt', '50 57 65 0 50 57 65 '),\n",
       " ('Undertale_-_Battle_Against_a_True_Hero.txt', '88 0 88 0 88 0 88 0 '),\n",
       " ('Undertale_-_Bonetrousle.txt', '37 0 37 0 37 0 37 0 '),\n",
       " ('Undertale_-_Heartache.txt', '31 47 0 31 47 0 31 4'),\n",
       " ('Undertale_-_Hopes_and_Dreams.txt', '64 78 0 64 78 0 64 7'),\n",
       " ('Undertale_-_Memory.txt', '77 0 77 0 77 0 77 0 '),\n",
       " ('Undertale_-_sans.txt', '33 0 33 0 33 0 33 0 '),\n",
       " ('Undertale_-_SAVE_the_World.txt', '45 57 67 0 45 57 67 '),\n",
       " ('Undertale_-_Spider_Dance.txt', '42 73 78 0 42 73 78 '),\n",
       " ('Undertale_Undertale_Piano.txt', '59 0 59 0 59 0 59 0 '),\n",
       " ('Vs._Susie_Deltarune_-_Arranged_for_Piano.txt', '47 0 47 0 47 0 47 0 ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(texts_dir):\n",
    "\n",
    "    if not os.path.isdir(texts_dir):\n",
    "        raise FileNotFoundError(\"given text directory not found: {}\".format(texts_dir))\n",
    "\n",
    "    texts = []\n",
    "    \n",
    "    for text_path in (file.path for file in os.scandir(texts_dir) if file.is_file() and file.name.endswith(\".txt\")):\n",
    "        with open(file=text_path, mode='r', encoding=\"utf-8\") as text_file:\n",
    "            \n",
    "            text = text_file.read().strip()\n",
    "\n",
    "            if not text.replace(' ', '').isdigit():\n",
    "                raise RuntimeError(\"one or more characters other than digits and white spaces are detected: {}\".format(text_path))\n",
    "\n",
    "            while \"  \" in text:\n",
    "                text = text.replace(\"  \", ' ')\n",
    "            \n",
    "            texts.append((text_path, text))\n",
    "    \n",
    "    return dict(texts)\n",
    "\n",
    "\n",
    "[(os.path.split(text_path)[1], text[:20]) for text_path, text in get_texts(\"./source/converted_texts\").items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get integers out of the text and make lists of ints.\n",
    "\n",
    "These lists can be used for the input of the models, or be further processed to compress or simplify the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T00:45:56.267919Z",
     "start_time": "2019-03-16T00:45:55.497915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 46, 49, 53, 0, 42, 46, 49, 53, 0], [73, 89, 0, 73, 89, 0, 73, 89, 0, 73], [39, 51, 0, 39, 51, 0, 39, 51, 0, 39], [48, 0, 48, 0, 48, 0, 48, 0, 48, 0], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [30, 0, 30, 0, 30, 0, 30, 0, 30, 0], [48, 55, 0, 48, 55, 0, 48, 55, 0, 48], [27, 39, 0, 27, 39, 0, 27, 39, 0, 27], [61, 64, 71, 75, 0, 61, 64, 71, 75, 0], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [74, 0, 74, 0, 74, 0, 74, 0, 74, 0], [32, 36, 39, 68, 0, 32, 36, 39, 68, 0], [62, 0, 62, 0, 62, 0, 0, 0, 0, 65], [0, 0, 0, 62, 0, 62, 0, 62, 0, 62], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [31, 43, 0, 31, 43, 0, 31, 43, 0, 31], [24, 31, 0, 24, 31, 0, 24, 31, 0, 24], [45, 57, 0, 45, 57, 0, 45, 57, 0, 45], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [46, 0, 46, 0, 46, 0, 46, 0, 46, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [58, 70, 0, 58, 70, 0, 58, 70, 0, 58], [37, 49, 0, 37, 49, 0, 37, 49, 0, 37], [44, 68, 0, 44, 68, 0, 44, 68, 0, 44], [67, 0, 67, 0, 67, 0, 67, 0, 67, 0], [61, 0, 61, 0, 61, 0, 61, 0, 61, 0], [49, 0, 49, 0, 49, 0, 49, 0, 54, 0], [43, 74, 0, 43, 74, 0, 43, 74, 0, 43], [55, 0, 55, 0, 55, 0, 55, 0, 55, 0], [38, 66, 0, 38, 66, 0, 38, 66, 0, 38], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [54, 0, 54, 0, 54, 0, 54, 0, 54, 0], [49, 80, 0, 49, 80, 0, 49, 80, 0, 49], [56, 68, 71, 78, 0, 56, 68, 71, 78, 0], [39, 61, 65, 0, 39, 61, 65, 0, 39, 61], [63, 79, 0, 63, 79, 0, 63, 79, 0, 63], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [40, 79, 0, 40, 79, 0, 40, 79, 0, 40], [65, 0, 65, 0, 65, 0, 65, 0, 65, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [32, 44, 68, 75, 80, 0, 32, 44, 68, 75], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0], [64, 0, 64, 0, 64, 0, 64, 0, 64, 0], [85, 0, 85, 0, 85, 0, 85, 0, 80, 0], [35, 0, 35, 0, 35, 0, 35, 0, 35, 0], [49, 0, 49, 0, 49, 52, 0, 49, 52, 56], [69, 72, 74, 0, 69, 72, 74, 0, 69, 72], [41, 0, 41, 0, 41, 0, 41, 0, 41, 0], [35, 47, 58, 70, 0, 35, 47, 58, 70, 0], [47, 54, 69, 0, 47, 54, 69, 0, 47, 54], [63, 0, 63, 0, 63, 0, 63, 0, 0, 63], [50, 57, 65, 0, 50, 57, 65, 0, 50, 57], [88, 0, 88, 0, 88, 0, 88, 0, 88, 0], [37, 0, 37, 0, 37, 0, 37, 0, 37, 0], [31, 47, 0, 31, 47, 0, 31, 47, 0, 31], [64, 78, 0, 64, 78, 0, 64, 78, 0, 64], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [33, 0, 33, 0, 33, 0, 33, 0, 33, 0], [45, 57, 67, 0, 45, 57, 67, 0, 45, 57], [42, 73, 78, 0, 42, 73, 78, 0, 73, 78], [59, 0, 59, 0, 59, 0, 59, 0, 59, 0], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0]]\n"
     ]
    }
   ],
   "source": [
    "def texts_to_intlists(text_list):\n",
    "    \n",
    "    intlists = []\n",
    "    \n",
    "    for i, text in enumerate(iterable=text_list):\n",
    "        \n",
    "        int_strings = text.split(' ')\n",
    "        \n",
    "        if not all(int_str.isdigit() for int_str in int_strings):\n",
    "            raise RuntimeError(\"non-digit string detected in text {}\".format(i))\n",
    "\n",
    "        ints = [int(int_str) for int_str in int_strings]\n",
    "        \n",
    "        intlists.append(ints)\n",
    "        \n",
    "    return intlists\n",
    "\n",
    "\n",
    "print([ints[:10] for ints in texts_to_intlists(get_texts(\"./source/converted_texts\").values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use \"words\" as the input and output instead of \"characters\",\n",
    "\n",
    "consider '0's as spaces and find all existing words in the texts.\n",
    "\n",
    "(Here, each word becomes a \"token\")\n",
    "\n",
    "We can also tokenize the duration of each word to reduce the\n",
    "\n",
    "repetition of words that appear several times in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T00:45:59.076935Z",
     "start_time": "2019-03-16T00:45:57.228922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536 tokens\n",
      "\n",
      "Part of tokenized sequences:\n",
      "[[764, 7535, 7535, 7535, 7535, 7535, 7535, 7535, 7535, 7535], [2871, 7535, 1336, 7535, 991, 1336, 7533, 262, 7521, 2872], [59, 7534, 0, 59, 7535, 7535, 7535, 7535, 7522, 2888], [25, 7535, 7521, 0, 50, 7535, 7521, 12, 7535, 7535], [23, 7524, 0, 7523, 23, 7524, 0, 7535, 7527, 121], [52, 7529, 0, 52, 7522, 0, 7535, 7535, 7535, 7535], [221, 7524, 0, 7522, 221, 7526, 0, 221, 7525, 0], [78, 7530, 0, 78, 7524, 0, 7525, 78, 7525, 0], [622, 7532, 166, 7526, 622, 7525, 166, 1374, 7528, 166], [16, 7535, 7533, 0, 7521, 26, 7535, 7533, 0, 1009]]\n",
      "\n",
      "Original lengths:\n",
      "[9070, 15651, 4602, 13185, 8139, 10348, 7383, 30509, 10821, 6219]\n",
      "\n",
      "Tokenized lengths (with maximum repetition of 15):\n",
      "[246, 892, 119, 641, 673, 1451, 719, 4066, 684, 307]\n",
      "\n",
      "Some of the most frequent tokens + repetition tokens if used:\n",
      "[(0, ()), (1, (44,)), (2, (69,)), (3, (66,)), (4, (63,)), (7531, ('<REPEAT>', 11)), (7532, ('<REPEAT>', 12)), (7533, ('<REPEAT>', 13)), (7534, ('<REPEAT>', 14)), (7535, ('<REPEAT>', 15))]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(intlists, max_repeat_encoding=0):\n",
    "    assert isinstance(max_repeat_encoding, int) and max_repeat_encoding >= -1 # -1 for no limit\n",
    "    \n",
    "    encode_repetition = (max_repeat_encoding != 0)\n",
    "    if encode_repetition:\n",
    "        observed_repeats = []\n",
    "    \n",
    "    counter = collections.Counter() # Note: repetition tokens are not counted. They are appended to the dictionary later.\n",
    "    tokenized_lists = []\n",
    "    \n",
    "    for intlist in intlists:\n",
    "        if encode_repetition:\n",
    "            last_token = None\n",
    "            n_repeats = 0\n",
    "        token = []\n",
    "        tokenized = []\n",
    "        for int_val in intlist:\n",
    "            if int_val != 0:\n",
    "                token.append(int_val)\n",
    "            else:\n",
    "                token = tuple(sorted(token))\n",
    "                \n",
    "                if encode_repetition:\n",
    "                    if last_token == token:\n",
    "                        if n_repeats == max_repeat_encoding:\n",
    "                            tokenized.append((\"<REPEAT>\", n_repeats))\n",
    "                            n_repeats = 1\n",
    "                        else:\n",
    "                            n_repeats += 1\n",
    "                            if n_repeats not in observed_repeats:\n",
    "                                observed_repeats.append(n_repeats)\n",
    "                    else:\n",
    "                        if n_repeats != 0:\n",
    "                            tokenized.append((\"<REPEAT>\", n_repeats))\n",
    "                        counter.update((token,))\n",
    "                        tokenized.append(token)\n",
    "                        last_token = token\n",
    "                        n_repeats = 0\n",
    "\n",
    "                else:\n",
    "                    counter.update((token,))\n",
    "                    tokenized.append(token)\n",
    "                token = []\n",
    "        tokenized_lists.append(tokenized)\n",
    "    \n",
    "    tokens_token_to_idx = collections.OrderedDict((token_key, i) for i, (token_key, _) in enumerate(counter.most_common()))\n",
    "    if encode_repetition:\n",
    "        tokens_token_to_idx.update([((\"<REPEAT>\", r), i) for i, r in enumerate(observed_repeats, len(tokens_token_to_idx))])\n",
    "    tokens_idx_to_token = collections.OrderedDict((i, token_key) for token_key, i in tokens_token_to_idx.items())\n",
    "    print(len(tokens_idx_to_token), \"tokens\")\n",
    "    \n",
    "    for tokenized in tokenized_lists:\n",
    "        for i, token_key in enumerate(tokenized):\n",
    "            tokenized[i] = tokens_token_to_idx[token_key]\n",
    "\n",
    "    return tokenized_lists, tokens_idx_to_token\n",
    "\n",
    "max_repeats = 15\n",
    "\n",
    "intlists = texts_to_intlists(get_texts(\"./source/converted_texts\").values())\n",
    "tokenized_lists, tokens_idx_to_token = tokenize(intlists, max_repeat_encoding=max_repeats)\n",
    "print(\"\\nPart of tokenized sequences:\")\n",
    "print([tokenized_list[:10] for tokenized_list in tokenized_lists[:10]])\n",
    "print(\"\\nOriginal lengths:\")\n",
    "print([len(intlist) for intlist in intlists[:10]])\n",
    "print(\"\\nTokenized lengths (with maximum repetition of {}):\".format(\"0 (no repetition tokens)\" if max_repeats == 0\n",
    "                                                                    else \"infinity (unlimited length)\" if max_repeats == -1\n",
    "                                                                    else max_repeats))\n",
    "print([len(tokenized_list) for tokenized_list in tokenized_lists[:10]])\n",
    "print(\"\\nSome of the most frequent tokens + repetition tokens if used:\")\n",
    "print(list(tokens_idx_to_token.items())[:5] + list(tokens_idx_to_token.items())[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you try out different *'max_repeat_encoding'* values \\[0, 5, 10, 20, -1\\] (-1 for unlimited repetition length)\n",
    "\n",
    "you should observe great reductions in sequence lengths when using repetition encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Create a Dataset class from which training data can be sampled.\n",
    "\n",
    "This Dataset should convert the encoded sequence above into tensors\n",
    "\n",
    "and have a method for shuffling the order of multiple sequences while\n",
    "\n",
    "leaving the patterns inside of each sequence untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T03:00:00.133670Z",
     "start_time": "2019-03-16T03:00:00.121670Z"
    }
   },
   "outputs": [],
   "source": [
    "class UndertaleDeltaruneDataset(Dataset):\n",
    "    def __init__(self, texts_dir, batch_size, max_repeats):\n",
    "        self.texts = get_texts(texts_dir) # read and get a dictionary of {file_paths: text_contents}\n",
    "        self.sequences, self.tokens = tokenize(texts_to_intlists((self.texts.values())), max_repeat_encoding=max_repeats) # convert and tokenize\n",
    "\n",
    "        self.texts_dir = texts_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def data_len(self):\n",
    "        return sum([len(sequence) for sequence in self.sequences])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        shuffled_list = list(itertools.chain(random.sample(self.sequences, len(self.sequences))))\n",
    "        return torch.LongTensor(shuffled_list[:-1]), torch.LongTensor(shuffled_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Define the model architecture.\n",
    "\n",
    "The input is indices of the tokens, and the output is the negative Euclidean distance between the output of the final fully-connected layer and each embedding vectors of the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T03:00:01.182670Z",
     "start_time": "2019-03-16T03:00:01.151732Z"
    }
   },
   "outputs": [],
   "source": [
    "class UDNet(nn.Module):\n",
    "    \"\"\"Undertale-Deltarune Network\"\"\"\n",
    "    def __init__(self, n_tokens, embedding_dim, hidden_dim, dropout=0., batch_first=True):\n",
    "        super(UDNet, self).__init__()\n",
    "        \n",
    "        # Stored variables\n",
    "        self.n_tokens = n_tokens\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "        # Overall architecture\n",
    "        self.embed = nn.Embedding(num_embeddings=n_tokens,      embedding_dim=embedding_dim)\n",
    "        self.lstm0 = nn.LSTM(     input_size    =embedding_dim, hidden_size  =hidden_dim,   batch_first=batch_first)\n",
    "        self.ln0   = nn.LayerNorm(hidden_dim)\n",
    "        self.lstm1 = nn.LSTM(     input_size    =hidden_dim,    hidden_size  =hidden_dim,   batch_first=batch_first)\n",
    "        self.ln1   = nn.LayerNorm(hidden_dim)\n",
    "        self.lstm2 = nn.LSTM(     input_size    =hidden_dim,    hidden_size  =hidden_dim,   batch_first=batch_first)\n",
    "        self.ln2   = nn.LayerNorm(hidden_dim)\n",
    "        self.fc    = nn.Linear(   in_features   =hidden_dim,    out_features =embedding_dim)\n",
    "        \n",
    "        # Parameterized initial hidden(hidden, cell) states\n",
    "        self.hidden0_0 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.  cell0_0 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.hidden0_1 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.  cell0_1 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.hidden0_2 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.  cell0_2 = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        \n",
    "        # Dropout and Activation layers\n",
    "        self.dropout_layer     = nn.Dropout(p=dropout)\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden_states):\n",
    "        hiddens, cells = hidden_states\n",
    "        hiddens, cells = list(hiddens), list(cells)\n",
    "\n",
    "        shortcut =        x       = self.embed(x)\n",
    "        x, (hiddens[0], cells[0]) = self.lstm0(         self.dropout_layer(x), (hiddens[0], cells[0]))\n",
    "        shortcut, x               = x, shortcut + x\n",
    "        x, (hiddens[1], cells[1]) = self.lstm1(self.ln0(self.dropout_layer(x)), (hiddens[1], cells[1]))\n",
    "        shortcut, x               = x, shortcut + x\n",
    "        x, (hiddens[2], cells[2]) = self.lstm2(self.ln1(self.dropout_layer(x)), (hiddens[2], cells[2]))\n",
    "        x                         =    shortcut + x\n",
    "        x                         = self.fc(   self.ln2(self.dropout_layer(x)))\n",
    "        # Euclidean distance in the embedding space\n",
    "        x                         = (x.unsqueeze(-2) - self.embed.weights).pow(2).sum(dim=-1, keepdim=False).sqrt()\n",
    "        \n",
    "        x = x.neg()\n",
    "        \n",
    "        return x, (tuple(hiddens), tuple(cells))\n",
    "\n",
    "    def init_hidden(self, cuda=None):\n",
    "        if cuda is None:\n",
    "            device = self.hidden0_0.device\n",
    "        else:\n",
    "            device = torch.device('cuda') if cuda else torch.device('cpu')\n",
    "        \n",
    "        hiddens = (\n",
    "            self.hidden0_0.to(device),\n",
    "            self.hidden0_1.to(device),\n",
    "            self.hidden0_2.to(device)\n",
    "        )\n",
    "\n",
    "        cells = (\n",
    "            self.cell0_0.to(device),\n",
    "            self.cell0_1.to(device),\n",
    "            self.cell0_2.to(device)\n",
    "        )\n",
    "        \n",
    "        return (hiddens, cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters & Instantiation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Set hyperparameters and instantiate a dataset and a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T03:00:22.805672Z",
     "start_time": "2019-03-16T03:00:21.204669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536 tokens\n",
      "88709\n",
      "UDNet(\n",
      "  (embed): Embedding(7536, 128)\n",
      "  (lstm0): LSTM(128, 256, batch_first=True)\n",
      "  (ln0): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (lstm1): LSTM(256, 256, batch_first=True)\n",
      "  (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (lstm2): LSTM(256, 256, batch_first=True)\n",
      "  (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (dropout_layer): Dropout(p=0.2)\n",
      "  (hidden_activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "max_repeats = 15\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "dropout=0.2\n",
    "\n",
    "ud_dataset = UndertaleDeltaruneDataset(\"./source/converted_texts\", 1, max_repeats)\n",
    "\n",
    "model = UDNet(len(ud_dataset.tokens), embedding_dim, hidden_dim, dropout)\n",
    "\n",
    "print(ud_dataset.data_len())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Saving Trained Model\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Generation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Generation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Summary, Notes, and Thoughts\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
