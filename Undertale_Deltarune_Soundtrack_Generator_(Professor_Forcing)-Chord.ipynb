{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undertale & Deltarune Soundtrack Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [**Table of Contents**](#Table-of-Contents)\n",
    "\n",
    "1. [**Imports**](#Imports)\n",
    "\n",
    "2. [**Data Processing**](#Data-Processing)\n",
    "\n",
    "    2.1 [Data Loading](#Data-Loading)\n",
    "    \n",
    "    2.2 [Data Preprocessing](#Data-Preprocessing)\n",
    "    \n",
    "    2.3 [Dataset & Dataloader Definition](#Dataset-&-Dataloader-Definition)\n",
    "    \n",
    "3. [**Model Definition**](#Model-Definition)\n",
    "    \n",
    "4. [**Hyperparameters & Instantiation**](#Hyperparameters-&-Instantiation)\n",
    "\n",
    "5. [**Training**](#Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:23:51.741653Z",
     "start_time": "2019-08-03T23:23:51.731681Z"
    }
   },
   "outputs": [],
   "source": [
    "import os                                         # File handling\n",
    "import itertools                                  # chain() for merging lists\n",
    "import random                                     # Shuffling\n",
    "import collections                                # Useful tools like Counter, OrderedDict\n",
    "import math                                       # For... math\n",
    "from decimal import Decimal                       # Scientific notations in string formatting\n",
    "from time import time                             # For use in progress bar\n",
    "\n",
    "import tqdm.auto as tqdm                          # Progress bar\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch                                      # Deep Learning Framework\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt                   # Plotting training progress\n",
    "from matplotlib.ticker import AutoLocator\n",
    "%matplotlib inline\n",
    "\n",
    "fig_bg_color = \"lightsteelblue\"\n",
    "plot_bg_color = \"slategray\"\n",
    "fontsize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T06:55:43.051798Z",
     "start_time": "2019-03-17T06:55:43.046023Z"
    }
   },
   "source": [
    "## Data Processing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Read the text files in the target directory.\n",
    "\n",
    "Do some processing to make sure the texts are clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:23.245656Z",
     "start_time": "2019-08-02T01:42:23.184856Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANOTHER_HIM_-_DeltaRune.txt', '42 46 49 53 0 42 46 '),\n",
       " ('A_Town_Called_Hometown_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '73 89 0 73 89 0 73 8'),\n",
       " ('Basement_Deltarune_-_Arranged_for_Piano.txt', '39 51 0 39 51 0 39 5'),\n",
       " ('Before_the_Story_Deltarune_-_Arranged_for_piano_.txt',\n",
       "  '48 0 48 0 48 0 48 0 '),\n",
       " ('Card_Castle_Deltarune_-_Arranged_for_Piano.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Checker_Dance_Deltarune_-_Arranged_for_Piano.txt', '30 0 30 0 30 0 30 0 '),\n",
       " ('Deltarune_-_Beginning.txt', '48 55 0 48 55 0 48 5'),\n",
       " ('Deltarune_-_Chaos_King.txt', '27 39 0 27 39 0 27 3'),\n",
       " ('Deltarune_-_Darkness_Falls.txt', '61 64 71 75 0 61 64 '),\n",
       " ('Deltarune_-_Dont_Forget_Ending_Theme_Solo_Piano_Version.txt',\n",
       "  '77 0 77 0 77 0 77 0 '),\n",
       " ('Deltarune_-_Friendship.txt', '74 0 74 0 74 0 74 0 '),\n",
       " ('Deltarune_-_Gallery.txt', '32 36 39 68 0 32 36 '),\n",
       " ('Deltarune_-_Lancer_Battle.txt', '62 0 62 0 62 0 0 0 0'),\n",
       " ('DELTARUNE_-_Lancer_piano_solo.txt', '0 0 0 62 0 62 0 62 0'),\n",
       " ('Deltarune_-_Lantern.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Deltarune_-_Rude_Buster_Playable.txt', '31 43 0 31 43 0 31 4'),\n",
       " ('Deltarune_-_The_Chase.txt', '24 31 0 24 31 0 24 3'),\n",
       " ('Deltarune_-_THE_WORLD_REVOLVING.txt', '45 57 0 45 57 0 45 5'),\n",
       " ('Deltarune_-_Thrash_Machine.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Deltarune_-_You_Can_Always_Come_Home.txt', '46 0 46 0 46 0 46 0 '),\n",
       " ('Deltarune_Legend.txt', '0 0 0 0 0 0 0 0 0 0 '),\n",
       " ('Empty_Town_Deltarune_-_Arranged_for_Piano.txt', '58 70 0 58 70 0 58 7'),\n",
       " ('Fanfare_Deltarune_-_Arranged_for_Piano.txt', '37 49 0 37 49 0 37 4'),\n",
       " ('Hip_Shop_Deltarune_-_Arranged_for_Piano.txt', '44 68 0 44 68 0 44 6'),\n",
       " ('Im_Very_Bad_Deltarune_-_Arranged_for_Piano.txt', '67 0 67 0 67 0 67 0 '),\n",
       " ('Man_Deltarune.txt', '61 0 61 0 61 0 61 0 '),\n",
       " ('Quiet_Autumn_Deltarune_-_Arranged_for_Piano.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Rouxls_Kaard.txt', '43 74 0 43 74 0 43 7'),\n",
       " ('Scarlet_Forest_-_Deltarune_Advanced_Piano.txt', '55 0 55 0 55 0 55 0 '),\n",
       " ('School_-_DeltaRune.txt', '38 66 0 38 66 0 38 6'),\n",
       " ('Susie_Deltarune_-_Arranged_for_Piano.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('The_Circus_Deltarune_-_Arranged_for_Piano.txt', '54 0 54 0 54 0 54 0 '),\n",
       " ('The_Door_Deltarune_-_Arranged_for_Piano.txt', '49 80 0 49 80 0 49 8'),\n",
       " ('The_Field_of_Hopes_and_Dreams_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '56 68 71 78 0 56 68 '),\n",
       " ('THE_HOLY_Deltarune_-_Arranged_for_Piano.txt', '39 61 65 0 39 61 65 '),\n",
       " ('Undertale_-_004_Fallen_Down__085_Fallen_Down_Reprise.txt',\n",
       "  '63 79 0 63 79 0 63 7'),\n",
       " ('Undertale_-_005_Ruins.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('Undertale_-_010_Ghost_Fight.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_011_Determination.txt', '40 79 0 40 79 0 40 7'),\n",
       " ('Undertale_-_031_Waterfall.txt', '65 0 65 0 65 0 65 0 '),\n",
       " ('Undertale_-_036_Dummy.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_043_Temmie_Village.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Undertale_-_046_Spear_of_Justice.txt', '32 44 68 75 80 0 32 '),\n",
       " ('Undertale_-_048_Alphys.txt', '47 0 47 0 47 0 47 0 '),\n",
       " ('Undertale_-_050_Metal_Crusher.txt', '64 0 64 0 64 0 64 0 '),\n",
       " ('Undertale_-_051_Another_Medium.txt', '85 0 85 0 85 0 85 0 '),\n",
       " ('Undertale_-_053_Stronger_Monsters.txt', '35 0 35 0 35 0 35 0 '),\n",
       " ('Undertale_-_063_Its_Raining_Somewhere_Else.txt', '49 0 49 0 49 52 0 49'),\n",
       " ('Undertale_-_065_CORE.txt', '69 72 74 0 69 72 74 '),\n",
       " ('Undertale_-_068_Death_by_Glamour.txt', '41 0 41 0 41 0 41 0 '),\n",
       " ('Undertale_-_079_Your_Best_Nightmare.txt', '35 47 58 70 0 35 47 '),\n",
       " ('Undertale_-_080_Finale.txt', '47 54 69 0 47 54 69 '),\n",
       " ('Undertale_-_100_MEGALOVANIA.txt', '63 0 63 0 63 0 63 0 '),\n",
       " ('Undertale_-_ASGORE.txt', '50 57 65 0 50 57 65 '),\n",
       " ('Undertale_-_Battle_Against_a_True_Hero.txt', '88 0 88 0 88 0 88 0 '),\n",
       " ('Undertale_-_Bonetrousle.txt', '37 0 37 0 37 0 37 0 '),\n",
       " ('Undertale_-_Heartache.txt', '31 47 0 31 47 0 31 4'),\n",
       " ('Undertale_-_Hopes_and_Dreams.txt', '64 78 0 64 78 0 64 7'),\n",
       " ('Undertale_-_Memory.txt', '77 0 77 0 77 0 77 0 '),\n",
       " ('Undertale_-_sans.txt', '33 0 33 0 33 0 33 0 '),\n",
       " ('Undertale_-_SAVE_the_World.txt', '45 57 67 0 45 57 67 '),\n",
       " ('Undertale_-_Spider_Dance.txt', '42 73 78 0 42 73 78 '),\n",
       " ('Undertale_Undertale_Piano.txt', '59 0 59 0 59 0 59 0 '),\n",
       " ('Vs._Susie_Deltarune_-_Arranged_for_Piano.txt', '47 0 47 0 47 0 47 0 ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(texts_dir):\n",
    "\n",
    "    if not os.path.isdir(texts_dir):\n",
    "        raise FileNotFoundError(\"given text directory not found: {}\".format(texts_dir))\n",
    "\n",
    "    texts = []\n",
    "    \n",
    "    for text_path in (file.path for file in os.scandir(texts_dir) if file.is_file() and file.name.endswith(\".txt\")):\n",
    "        with open(file=text_path, mode='r', encoding=\"utf-8\") as text_file:\n",
    "            \n",
    "            text = text_file.read().strip()\n",
    "\n",
    "            if not text.replace(' ', '').isdigit():\n",
    "                raise RuntimeError(\"one or more characters other than digits and white spaces are detected: {}\".format(text_path))\n",
    "\n",
    "            while \"  \" in text:\n",
    "                text = text.replace(\"  \", ' ')\n",
    "            \n",
    "            texts.append((text_path, text))\n",
    "    \n",
    "    return dict(texts)\n",
    "\n",
    "\n",
    "[(os.path.split(text_path)[1], text[:20]) for text_path, text in get_texts(\"./source/converted_texts\").items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get integers out of the text and make lists of ints.\n",
    "\n",
    "These lists can be used for the input of the models, or be further processed to compress or simplify the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:24.019791Z",
     "start_time": "2019-08-02T01:42:23.658768Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 46, 49, 53, 0, 42, 46, 49, 53, 0], [73, 89, 0, 73, 89, 0, 73, 89, 0, 73], [39, 51, 0, 39, 51, 0, 39, 51, 0, 39], [48, 0, 48, 0, 48, 0, 48, 0, 48, 0], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [30, 0, 30, 0, 30, 0, 30, 0, 30, 0], [48, 55, 0, 48, 55, 0, 48, 55, 0, 48], [27, 39, 0, 27, 39, 0, 27, 39, 0, 27], [61, 64, 71, 75, 0, 61, 64, 71, 75, 0], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [74, 0, 74, 0, 74, 0, 74, 0, 74, 0], [32, 36, 39, 68, 0, 32, 36, 39, 68, 0], [62, 0, 62, 0, 62, 0, 0, 0, 0, 65], [0, 0, 0, 62, 0, 62, 0, 62, 0, 62], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [31, 43, 0, 31, 43, 0, 31, 43, 0, 31], [24, 31, 0, 24, 31, 0, 24, 31, 0, 24], [45, 57, 0, 45, 57, 0, 45, 57, 0, 45], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [46, 0, 46, 0, 46, 0, 46, 0, 46, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [58, 70, 0, 58, 70, 0, 58, 70, 0, 58], [37, 49, 0, 37, 49, 0, 37, 49, 0, 37], [44, 68, 0, 44, 68, 0, 44, 68, 0, 44], [67, 0, 67, 0, 67, 0, 67, 0, 67, 0], [61, 0, 61, 0, 61, 0, 61, 0, 61, 0], [49, 0, 49, 0, 49, 0, 49, 0, 54, 0], [43, 74, 0, 43, 74, 0, 43, 74, 0, 43], [55, 0, 55, 0, 55, 0, 55, 0, 55, 0], [38, 66, 0, 38, 66, 0, 38, 66, 0, 38], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [54, 0, 54, 0, 54, 0, 54, 0, 54, 0], [49, 80, 0, 49, 80, 0, 49, 80, 0, 49], [56, 68, 71, 78, 0, 56, 68, 71, 78, 0], [39, 61, 65, 0, 39, 61, 65, 0, 39, 61], [63, 79, 0, 63, 79, 0, 63, 79, 0, 63], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [40, 79, 0, 40, 79, 0, 40, 79, 0, 40], [65, 0, 65, 0, 65, 0, 65, 0, 65, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [32, 44, 68, 75, 80, 0, 32, 44, 68, 75], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0], [64, 0, 64, 0, 64, 0, 64, 0, 64, 0], [85, 0, 85, 0, 85, 0, 85, 0, 80, 0], [35, 0, 35, 0, 35, 0, 35, 0, 35, 0], [49, 0, 49, 0, 49, 52, 0, 49, 52, 56], [69, 72, 74, 0, 69, 72, 74, 0, 69, 72], [41, 0, 41, 0, 41, 0, 41, 0, 41, 0], [35, 47, 58, 70, 0, 35, 47, 58, 70, 0], [47, 54, 69, 0, 47, 54, 69, 0, 47, 54], [63, 0, 63, 0, 63, 0, 63, 0, 0, 63], [50, 57, 65, 0, 50, 57, 65, 0, 50, 57], [88, 0, 88, 0, 88, 0, 88, 0, 88, 0], [37, 0, 37, 0, 37, 0, 37, 0, 37, 0], [31, 47, 0, 31, 47, 0, 31, 47, 0, 31], [64, 78, 0, 64, 78, 0, 64, 78, 0, 64], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [33, 0, 33, 0, 33, 0, 33, 0, 33, 0], [45, 57, 67, 0, 45, 57, 67, 0, 45, 57], [42, 73, 78, 0, 42, 73, 78, 0, 73, 78], [59, 0, 59, 0, 59, 0, 59, 0, 59, 0], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0]]\n"
     ]
    }
   ],
   "source": [
    "def texts_to_intlists(text_list):\n",
    "    \n",
    "    intlists = []\n",
    "    \n",
    "    for i, text in enumerate(iterable=text_list):\n",
    "        \n",
    "        int_strings = text.split(' ')\n",
    "        \n",
    "        if not all(int_str.isdigit() for int_str in int_strings):\n",
    "            raise RuntimeError(\"non-digit string detected in text {}\".format(i))\n",
    "\n",
    "        ints = [int(int_str) for int_str in int_strings]\n",
    "        \n",
    "        intlists.append(ints)\n",
    "        \n",
    "    return intlists\n",
    "\n",
    "\n",
    "print([ints[:10] for ints in texts_to_intlists(get_texts(\"./source/converted_texts\").values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use \"words\" as the input and output instead of \"characters\",\n",
    "\n",
    "consider '0's as spaces and find all existing words in the texts.\n",
    "\n",
    "(Here, each word becomes a \"token\")\n",
    "\n",
    "We can also tokenize the duration of each word to reduce the\n",
    "\n",
    "repetition of words that appear several times in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:24.900028Z",
     "start_time": "2019-08-02T01:42:24.022783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536 tokens\n",
      "\n",
      "Part of tokenized sequences:\n",
      "[[764, 7535, 7535, 7535, 7535, 7535, 7535, 7535, 7535, 7535], [2871, 7535, 1336, 7535, 991, 1336, 7533, 262, 7521, 2872], [59, 7534, 0, 59, 7535, 7535, 7535, 7535, 7522, 2888], [25, 7535, 7521, 0, 50, 7535, 7521, 12, 7535, 7535], [23, 7524, 0, 7523, 23, 7524, 0, 7535, 7527, 121], [52, 7529, 0, 52, 7522, 0, 7535, 7535, 7535, 7535], [221, 7524, 0, 7522, 221, 7526, 0, 221, 7525, 0], [78, 7530, 0, 78, 7524, 0, 7525, 78, 7525, 0], [622, 7532, 166, 7526, 622, 7525, 166, 1374, 7528, 166], [16, 7535, 7533, 0, 7521, 26, 7535, 7533, 0, 1009]]\n",
      "\n",
      "Original lengths:\n",
      "[9070, 15651, 4602, 13185, 8139, 10348, 7383, 30509, 10821, 6219]\n",
      "\n",
      "Tokenized lengths (with maximum repetition of 15):\n",
      "[246, 892, 119, 641, 673, 1451, 719, 4066, 684, 307]\n",
      "\n",
      "Some of the most frequent tokens + repetition tokens if used:\n",
      "[(0, ()), (1, (44,)), (2, (69,)), (3, (66,)), (4, (63,)), (7531, ('<REPEAT>', 11)), (7532, ('<REPEAT>', 12)), (7533, ('<REPEAT>', 13)), (7534, ('<REPEAT>', 14)), (7535, ('<REPEAT>', 15))]\n",
      "\n",
      "Top 50%\n",
      "=========\n",
      "()                            8.319%\n",
      "('<REPEAT>', 3)               7.929%\n",
      "('<REPEAT>', 2)               5.626%\n",
      "('<REPEAT>', 4)               5.304%\n",
      "('<REPEAT>', 5)               4.827%\n",
      "('<REPEAT>', 1)               3.629%\n",
      "('<REPEAT>', 6)               3.332%\n",
      "('<REPEAT>', 7)               2.952%\n",
      "('<REPEAT>', 15)              2.831%\n",
      "('<REPEAT>', 8)               1.700%\n",
      "('<REPEAT>', 10)              1.302%\n",
      "('<REPEAT>', 9)               1.037%\n",
      "('<REPEAT>', 12)              0.587%\n",
      "('<REPEAT>', 13)              0.469%\n",
      "('<REPEAT>', 11)              0.466%\n"
     ]
    }
   ],
   "source": [
    "def tokenize(intlists, max_repeat_encoding=0, return_ratios=False):\n",
    "    assert isinstance(max_repeat_encoding, int) and max_repeat_encoding >= -1 # -1 for no limit\n",
    "    \n",
    "    encode_repetition = (max_repeat_encoding != 0)\n",
    "    if encode_repetition:\n",
    "        observed_repeats = []\n",
    "    \n",
    "    counter = collections.Counter() # Note: repetition tokens are not counted. They are appended to the dictionary later.\n",
    "    if return_ratios:\n",
    "        measure = collections.Counter()\n",
    "    tokenized_lists = []\n",
    "    \n",
    "    for intlist in intlists:\n",
    "        if encode_repetition:\n",
    "            last_token = None\n",
    "            n_repeats = 0\n",
    "        token = []\n",
    "        tokenized = []\n",
    "        for int_val in intlist:\n",
    "            if int_val != 0:\n",
    "                token.append(int_val)\n",
    "            else:\n",
    "                token = tuple(sorted(token))\n",
    "                \n",
    "                if encode_repetition:\n",
    "                    if last_token == token:\n",
    "                        if n_repeats == max_repeat_encoding:\n",
    "                            tokenized.append((\"<REPEAT>\", n_repeats))\n",
    "                            if return_ratios:\n",
    "                                measure.update(((\"<REPEAT>\", n_repeats),))\n",
    "                            n_repeats = 1\n",
    "                        else:\n",
    "                            n_repeats += 1\n",
    "                            if n_repeats not in observed_repeats:\n",
    "                                observed_repeats.append(n_repeats)\n",
    "                    else:\n",
    "                        if n_repeats != 0:\n",
    "                            tokenized.append((\"<REPEAT>\", n_repeats))\n",
    "                            if return_ratios:\n",
    "                                measure.update(((\"<REPEAT>\", n_repeats),))\n",
    "                        counter.update((token,))\n",
    "                        if return_ratios:\n",
    "                            measure.update((token,))\n",
    "                        tokenized.append(token)\n",
    "                        last_token = token\n",
    "                        n_repeats = 0\n",
    "\n",
    "                else:\n",
    "                    counter.update((token,))\n",
    "                    if return_ratios:\n",
    "                        measure.update((token,))\n",
    "                    tokenized.append(token)\n",
    "                token = []\n",
    "        tokenized_lists.append(tokenized)\n",
    "    \n",
    "    tokens_token_to_idx = collections.OrderedDict((token_key, i) for i, (token_key, _) in enumerate(counter.most_common()))\n",
    "    if encode_repetition:\n",
    "        tokens_token_to_idx.update([((\"<REPEAT>\", r), i) for i, r in enumerate(observed_repeats, len(tokens_token_to_idx))])\n",
    "    tokens_idx_to_token = collections.OrderedDict((i, token_key) for token_key, i in tokens_token_to_idx.items())\n",
    "    print(len(tokens_idx_to_token), \"tokens\")\n",
    "    \n",
    "    if return_ratios:\n",
    "        n_total_tokens = sum(tuple(measure.values()))\n",
    "        ratios = collections.OrderedDict((token_key, n_occurs / n_total_tokens) for token_key, n_occurs in measure.most_common())\n",
    "    \n",
    "    for tokenized in tokenized_lists:\n",
    "        for i, token_key in enumerate(tokenized):\n",
    "            tokenized[i] = tokens_token_to_idx[token_key]\n",
    "\n",
    "    if return_ratios:\n",
    "        return tokenized_lists, tokens_idx_to_token, ratios\n",
    "    return tokenized_lists, tokens_idx_to_token\n",
    "\n",
    "\n",
    "max_repeats = 15\n",
    "\n",
    "intlists = texts_to_intlists(get_texts(\"./source/converted_texts\").values())\n",
    "tokenized_lists, tokens_idx_to_token, ratios = tokenize(intlists, max_repeat_encoding=max_repeats, return_ratios=True)\n",
    "print(\"\\nPart of tokenized sequences:\")\n",
    "print([tokenized_list[:10] for tokenized_list in tokenized_lists[:10]])\n",
    "print(\"\\nOriginal lengths:\")\n",
    "print([len(intlist) for intlist in intlists[:10]])\n",
    "print(\"\\nTokenized lengths (with maximum repetition of {}):\".format(\"0 (no repetition tokens)\" if max_repeats == 0\n",
    "                                                                    else \"infinity (unlimited length)\" if max_repeats == -1\n",
    "                                                                    else max_repeats))\n",
    "print([len(tokenized_list) for tokenized_list in tokenized_lists[:10]])\n",
    "print(\"\\nSome of the most frequent tokens + repetition tokens if used:\")\n",
    "print(list(tokens_idx_to_token.items())[:5] + list(tokens_idx_to_token.items())[-5:])\n",
    "\n",
    "print(\"\\nTop 50%\")\n",
    "print(\"=========\")\n",
    "cum_ratio_sum = 0\n",
    "for token_key, ratio in ratios.items():\n",
    "    print(\"{:<20s}{:>15.3f}%\".format(str(token_key), ratio * 100))\n",
    "    cum_ratio_sum += ratio\n",
    "    if cum_ratio_sum >= 0.5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you try out different *'max_repeat_encoding'* values \\[0, 5, 10, 20, -1\\] (-1 for unlimited repetition length)\n",
    "\n",
    "you should observe great reductions in sequence lengths when using repetition encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset class from which training data can be sampled.\n",
    "\n",
    "This Dataset should convert the encoded sequence above into tensors\n",
    "\n",
    "and have a method for shuffling the order of multiple sequences while\n",
    "\n",
    "leaving the patterns inside of each sequence untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:24.916982Z",
     "start_time": "2019-08-02T01:42:24.901025Z"
    }
   },
   "outputs": [],
   "source": [
    "class UndertaleDeltaruneDataset(Dataset):\n",
    "    def __init__(self, texts_dir, batch_size=1, max_repeats=15):\n",
    "        self.texts = get_texts(texts_dir) # read and get a dictionary of {file_paths: text_contents}\n",
    "        self.sequences, self.tokens = tokenize(texts_to_intlists((self.texts.values())), max_repeat_encoding=max_repeats) # convert and tokenize\n",
    "\n",
    "        self.texts_dir = texts_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def data_len(self):\n",
    "        return sum([len(sequence) for sequence in self.sequences])\n",
    "    \n",
    "    def update_tokens(self, new_tokens):\n",
    "        if len(self.tokens) != len(new_tokens):\n",
    "            raise ValueError(\"Token dictionary sizes mismatch - old: {} | new: {}\".format(len(self.tokens), len(new_tokens)))\n",
    "        \n",
    "        new_token_value_to_idx = collections.OrderedDict((v, k) for k, v in new_tokens.items())\n",
    "        \n",
    "        for old_key, old_val in self.tokens.items():\n",
    "            if old_val not in new_token_value_to_idx:\n",
    "                raise ValueError(\"Old [{}] value {} not found in the new tokens\".format(old_key, old_val))\n",
    "        \n",
    "        self.sequences = [[new_token_value_to_idx[self.tokens[old_key]] for old_key in sequence]\n",
    "                          for sequence in self.sequences]\n",
    "        self.tokens    = new_tokens\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        shuffled_list = list(itertools.chain(*random.sample(self.sequences, len(self.sequences))))\n",
    "        return torch.LongTensor(shuffled_list[:-1]), torch.LongTensor(shuffled_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom class that loads the data from the dataset above and\n",
    "\n",
    "allows iteration over the dataset, yielding a small sequence batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:25.231142Z",
     "start_time": "2019-08-02T01:42:25.220172Z"
    }
   },
   "outputs": [],
   "source": [
    "class UDBatchLoader:\n",
    "    def __init__(self, ud_dataset, batch_size, sequence_len, drop_last=False, batch_first=True):\n",
    "        self.ud_dataset = ud_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.drop_last = drop_last\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return math.floor((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "        return math.ceil((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "    \n",
    "    def generator(self):\n",
    "        seq_len = self.sequence_len\n",
    "        n_seq_batches = self.__len__()\n",
    "        batch_first = self.batch_first\n",
    "        \n",
    "        input_batch, target_batch = next(iter(DataLoader(self.ud_dataset, self.batch_size)))\n",
    "        if not batch_first:\n",
    "            input_batch = input_batch.transpose(0, 1).contiguous()\n",
    "            target_batch = target_batch.transpose(0, 1).contiguous()\n",
    "        \n",
    "        for start, end in zip(range(0, seq_len * n_seq_batches, seq_len), range(seq_len, (seq_len + 1) * n_seq_batches, seq_len)):\n",
    "            if batch_first:\n",
    "                yield (input_batch[:, start:end].contiguous(), target_batch[:, start:end].contiguous())\n",
    "            else:\n",
    "                yield (input_batch[start:end], target_batch[start:end])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Define the model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:26.352342Z",
     "start_time": "2019-08-02T01:42:26.336399Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_tokens):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_hidden0 = nn.Parameter(torch.randn(1, 1, 256))\n",
    "        self.init_hidden1 = nn.Parameter(torch.randn(1, 1, 256))\n",
    "        self.init_hidden2 = nn.Parameter(torch.randn(1, 1, 256))\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=n_tokens, embedding_dim=128)\n",
    "\n",
    "        self.norm0 = nn.LayerNorm(128)\n",
    "        self.gru0  = nn.GRU(input_size=128, hidden_size=256, batch_first=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(256)\n",
    "        self.gru1  = nn.GRU(input_size=256, hidden_size=256, batch_first=True)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(256)\n",
    "        self.gru2  = nn.GRU(input_size=256, hidden_size=256, batch_first=True)\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(in_features=256, out_features=512)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(in_features=512, out_features=256)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(in_features=256, out_features=n_tokens)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hiddens=None, return_all_hiddens=False):\n",
    "        if hiddens is None:\n",
    "            hiddens = self.get_init_hiddens(x.size(0))\n",
    "\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens = []\n",
    "\n",
    "        x = self.embed(x)\n",
    "\n",
    "        x, new_hidden0 = self.gru0(self.norm0(x), hiddens[0])\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "        x, new_hidden1 = self.gru1(self.norm1(x), hiddens[1])\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "        x, new_hidden2 = self.gru2(self.norm2(x), hiddens[2])\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if return_all_hiddens:\n",
    "            return x, [new_hidden0, new_hidden1, new_hidden2], internal_hiddens\n",
    "        return x, [new_hidden0, new_hidden1, new_hidden2]\n",
    "\n",
    "    def get_init_hiddens(self, n_batches):\n",
    "        return [self.init_hidden0.repeat(1, n_batches, 1),\n",
    "                self.init_hidden1.repeat(1, n_batches, 1),\n",
    "                self.init_hidden2.repeat(1, n_batches, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:26.769860Z",
     "start_time": "2019-08-02T01:42:26.753857Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.init_hidden0 = nn.Parameter(torch.randn(2, 1, 128))\n",
    "        self.init_hidden1 = nn.Parameter(torch.randn(2, 1, 128))\n",
    "        self.init_hidden2 = nn.Parameter(torch.randn(2, 1, 128))\n",
    "\n",
    "        self.norm0 = nn.LayerNorm(768)\n",
    "        self.gru0  = nn.GRU(input_size=768, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(256)\n",
    "        self.gru1  = nn.GRU(input_size=256, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(256)\n",
    "        self.gru2  = nn.GRU(input_size=256, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(in_features=256, out_features=512)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(in_features=512, out_features=256)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(in_features=256, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hiddens=None):\n",
    "        if hiddens is None:\n",
    "            hiddens = self.get_init_hiddens(x.size(0))\n",
    "\n",
    "        x, new_hidden0 = self.gru0(self.norm0(x), hiddens[0])\n",
    "        x, new_hidden1 = self.gru1(self.norm1(x), hiddens[1])\n",
    "        x, new_hidden2 = self.gru2(self.norm2(x), hiddens[2])\n",
    "\n",
    "        ### Consider only the final outputs from both directions by:\n",
    "        ### 1) separating the directions,\n",
    "        ### 2) taking the last timestep's output for forward direction([:, -1, 0, :])\n",
    "        ###    and the first timestep's output for backward direction([:, 0, 1, :]),\n",
    "        ### 3) then fianlly resizing the selected output into [n_batch, features] form.\n",
    "        x = x.view(*x.shape[:-1], 2, -1)[:, [-1, 0], [0, 1], :].view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, [new_hidden0, new_hidden1, new_hidden2]\n",
    "\n",
    "    def get_init_hiddens(self, n_batches):\n",
    "        return [self.init_hidden0.repeat(1, n_batches, 1),\n",
    "                self.init_hidden1.repeat(1, n_batches, 1),\n",
    "                self.init_hidden2.repeat(1, n_batches, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:27.390466Z",
     "start_time": "2019-08-02T01:42:27.382488Z"
    }
   },
   "outputs": [],
   "source": [
    "def free_running_generation(generator, inputs, seq_len, return_all_hiddens=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    generator (Generator): the generator model.\n",
    "    inputs (LongTensor): 2D tensor with dimensions [n_batches, 1].\n",
    "                         If the given dimensions are [n_batches, seq_len],\n",
    "                         then only the first timestep is used.\n",
    "    seq_len (int): length of sequence to generate.\n",
    "    return_all_hiddens (bool, optional): whether to retrieve the internal hidden states\n",
    "                                         for all timesteps from every RNN layer. (default: False)\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    output_sequence (LongTensor): tensor of generated outputs.\n",
    "    hiddens (list[Tensor]): updated hidden states.\n",
    "    internal_hiddens (list[Tensor]): list of tensors containing internal hidden states\n",
    "                                     for all timesteps from every RNN layer. Returned only\n",
    "                                     if `return_all_hiddens` is True.\n",
    "    \"\"\"\n",
    "    output_sequence = []\n",
    "    if return_all_hiddens:\n",
    "        internal_hiddens = []\n",
    "\n",
    "    hiddens = generator.get_init_hiddens(inputs.size(0))\n",
    "    x = inputs[:, :1]\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        if return_all_hiddens:\n",
    "            y, hiddens, current_internal_hiddens = generator(x, hiddens, return_all_hiddens=True)\n",
    "            internal_hiddens.append(current_internal_hiddens)\n",
    "        else:\n",
    "            y, hiddens = generator(x, hiddens, return_all_hiddens=False)\n",
    "        y = torch.multinomial(y.squeeze(1).softmax(dim=-1), num_samples=1)\n",
    "        output_sequence.append(y)\n",
    "        x = y\n",
    "    output_sequence = torch.cat(output_sequence, dim=1)\n",
    "    \n",
    "    if return_all_hiddens:\n",
    "        internal_hiddens = [torch.cat(layer_hiddens, dim=1) for layer_hiddens in zip(*internal_hiddens)]\n",
    "        return output_sequence, hiddens, internal_hiddens\n",
    "    return output_sequence, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:27.621693Z",
     "start_time": "2019-08-02T01:42:27.613749Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(discriminator, output_teacher, target_teacher, b_seq_teacher, b_seq_free,\n",
    "                   teacher_forcing_loss=True, free_teacher_behavior_loss=True, teacher_free_behavior_loss=True):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    discriminator (Discriminator): the Discriminator model.\n",
    "    output_teacher (Tensor): output of the Generator during teacher-forcing mode.\n",
    "    target_teacher (Tensor): target for the Generator during teacher-forcing mode.\n",
    "    b_seq_teacher (Tensor): behavior sequence from Generator during teacher-forcing mode.\n",
    "                            Must have dimensions [n_batches, seq_len, behavior_size].\n",
    "    b_seq_free (Tensor): behavior sequence from Generator during free-running mode.\n",
    "                         Assumed to have the same dimensionality as `b_seq_teacher`.\n",
    "    teacher_forcing_loss (bool): whether to calculate and return the loss for teacher-forced training. (default: True)\n",
    "    free_teacher_behavior_loss (bool): whether to calculate and return the loss for matching the\n",
    "                                       free-running behavior to the teacher-forced behavior.(default: True)\n",
    "    teacher_free_behavior_loss (bool): whether to calculate and return the loss for matching the\n",
    "                                       teacher-forced behavior to the free-running behavior.(default: True)\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    teacher_forcing_loss (Tensor): loss for maximizing the likelihood of the data\n",
    "                                   during teacher-forcing mode. Returned if\n",
    "                                   `teacher_forcing_loss` is True.\n",
    "    free_teacher_behavior_loss (Tensor): loss for changing the free-running behavior so that\n",
    "                                         it better matches the teacher-forced behavior,\n",
    "                                         considering the latter fixed. Returned if\n",
    "                                         `free_teacher_behavior_loss` is True.\n",
    "    teacher_free_behavior_loss (Tensor): loss for making the teacher-forced behavior\n",
    "                                         indistinguishable from the free-running behavior.\n",
    "                                         Returned if `teacher_free_behavior_loss` is True.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    if teacher_forcing_loss:\n",
    "        losses.append(F.cross_entropy(output_teacher.view(-1, output_teacher.size(-1)), target_teacher.view(-1)))\n",
    "\n",
    "    if free_teacher_behavior_loss:\n",
    "        hiddens = discriminator.get_init_hiddens(n_batches=b_seq_free.size(0))\n",
    "        raw_preds, _ = discriminator(b_seq_free, hiddens)\n",
    "        losses.append(F.binary_cross_entropy_with_logits(raw_preds, torch.ones_like(raw_preds)))\n",
    "\n",
    "    if teacher_free_behavior_loss:\n",
    "        hiddens = discriminator.get_init_hiddens(n_batches=b_seq_teacher.size(0))\n",
    "        raw_preds, _ = discriminator(b_seq_teacher, hiddens)\n",
    "        losses.append(F.binary_cross_entropy_with_logits(raw_preds, torch.zeros_like(raw_preds)))\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:27.862086Z",
     "start_time": "2019-08-02T01:42:27.851117Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator, b_seq_teacher, b_seq_free, return_acc=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    discriminator (Discriminator): the Discriminator model.\n",
    "    b_seq_teacher (Tensor): behavior sequence from Generator during teacher-forcing mode.\n",
    "                            Must have dimensions [n_batches, seq_len, behavior_size].\n",
    "    b_seq_free (Tensor): behavior sequence from Generator during free-running mode.\n",
    "                         Assumed to have the same dimensionality as `b_seq_teacher`.\n",
    "    return_acc (bool): whether to return the Discriminator accuracy or not. (default: False)\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    discriminator_loss (Tensor): the Discriminator loss as a scalar tensor.\n",
    "    discriminator_acc (float): accuracy of the Discriminator for the given data.\n",
    "                               Returned only if `return_acc` is True.\n",
    "    \"\"\"\n",
    "    ### Ensure that gradients will flow only through the discriminator and not the generator\n",
    "    b_seq_teacher = b_seq_teacher.detach()\n",
    "    b_seq_free    = b_seq_free.detach()\n",
    "\n",
    "    inputs  = torch.cat([b_seq_teacher, b_seq_free], dim=0)\n",
    "    targets = torch.cat([b_seq_teacher.new_ones(b_seq_teacher.size(0), 1),\n",
    "                         b_seq_free.new_zeros(b_seq_free.size(0), 1)], dim=0)\n",
    "\n",
    "    hiddens = discriminator.get_init_hiddens(n_batches=inputs.size(0))\n",
    "    raw_preds, _ = discriminator(inputs, hiddens)\n",
    "\n",
    "    if return_acc:\n",
    "        preds = raw_preds.sigmoid()\n",
    "\n",
    "        discriminator_loss = F.binary_cross_entropy(preds, targets, reduction='none')\n",
    "        discriminator_loss = discriminator_loss[:b_seq_teacher.size(0)].mean() + discriminator_loss[b_seq_teacher.size(0):].mean() ### Calculate separate average losses\n",
    "        discriminator_acc  = (preds.gt(0.5) == targets.byte()).float().mean().item()\n",
    "\n",
    "        return discriminator_loss, discriminator_acc\n",
    "\n",
    "    else:\n",
    "        discriminator_loss = F.binary_cross_entropy_with_logits(raw_preds, targets, reduction='none')\n",
    "        discriminator_loss = discriminator_loss[:b_seq_teacher.size(0)].mean() + discriminator_loss[b_seq_teacher.size(0):].mean() ### Calculate separate average losses\n",
    "\n",
    "        return discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:42:33.261927Z",
     "start_time": "2019-08-02T01:42:28.518692Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536 tokens\n",
      "\n",
      "Data Sequence Total Length: 88709\n",
      "\n",
      "Generator(\n",
      "  (embed): Embedding(7536, 128)\n",
      "  (norm0): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru0): GRU(128, 256, batch_first=True)\n",
      "  (norm1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru1): GRU(256, 256, batch_first=True)\n",
      "  (norm2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru2): GRU(256, 256, batch_first=True)\n",
      "  (fc0): Sequential(\n",
      "    (0): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=256, out_features=7536, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Discriminator(\n",
      "  (norm0): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru0): GRU(768, 128, batch_first=True, bidirectional=True)\n",
      "  (norm1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru1): GRU(256, 128, batch_first=True, bidirectional=True)\n",
      "  (norm2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "  (gru2): GRU(256, 128, batch_first=True, bidirectional=True)\n",
      "  (fc0): Sequential(\n",
      "    (0): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "seed                   = 0\n",
    "n_epochs               = 1000\n",
    "batch_size             = 32\n",
    "sequence_length        = 500\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "ud_dataset = UndertaleDeltaruneDataset(\"./source/converted_texts\", batch_size)\n",
    "ud_loader = UDBatchLoader(ud_dataset, batch_size, sequence_length, drop_last=False, batch_first=True)\n",
    "\n",
    "generator     = Generator(n_tokens=len(ud_dataset.tokens)).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "generator_optimizer     = optim.Adam(generator.parameters(), lr=5e-5)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "history = {}\n",
    "\n",
    "print()\n",
    "print('Data Sequence Total Length:', ud_dataset.data_len())\n",
    "print()\n",
    "print(generator)\n",
    "print()\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:11:37.069828Z",
     "start_time": "2019-08-02T01:42:33.263922Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_always_on = True\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    for inputs, targets in ud_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        teacher_forcing_outputs, _, teacher_internal_hiddens = generator(inputs, return_all_hiddens=True)\n",
    "        generated_sequence,      _, free_internal_hiddens    = free_running_generation(generator, inputs, inputs.size(1), return_all_hiddens=True)\n",
    "\n",
    "        b_seq_teacher = torch.cat(teacher_internal_hiddens, dim=-1)\n",
    "        b_seq_free    = torch.cat(free_internal_hiddens,    dim=-1)\n",
    "\n",
    "        D_loss, D_acc = discriminator_loss(discriminator, b_seq_teacher, b_seq_free, return_acc=True)\n",
    "\n",
    "        if D_acc < 0.99: # If too good, don't train the Discriminator\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            D_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "        D_loss = D_loss.item()\n",
    "\n",
    "        if D_acc > 0.75: # If too bad, don't use the Discriminator to train the Generator\n",
    "            t_force_loss, ft_b_loss, tf_b_loss = generator_loss(discriminator, teacher_forcing_outputs, targets,\n",
    "                                                                b_seq_teacher, b_seq_free,\n",
    "                                                                teacher_forcing_loss=True,\n",
    "                                                                free_teacher_behavior_loss=True,\n",
    "                                                                teacher_free_behavior_loss=True)\n",
    "\n",
    "            G_loss = (t_force_loss + ft_b_loss + tf_b_loss) / 3\n",
    "\n",
    "            generator_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            G_loss       = G_loss.item()\n",
    "            t_force_loss = t_force_loss.item()\n",
    "            ft_b_loss    = ft_b_loss.item()\n",
    "            tf_b_loss    = tf_b_loss.item()\n",
    "        else:\n",
    "            if teacher_forcing_always_on:\n",
    "                t_force_loss,                      = generator_loss(discriminator, teacher_forcing_outputs, targets,\n",
    "                                                                    b_seq_teacher, b_seq_free,\n",
    "                                                                    teacher_forcing_loss=True,\n",
    "                                                                    free_teacher_behavior_loss=False,\n",
    "                                                                    teacher_free_behavior_loss=False)\n",
    "\n",
    "                G_loss = t_force_loss\n",
    "\n",
    "                generator_optimizer.zero_grad()\n",
    "                G_loss.backward()\n",
    "                generator_optimizer.step()\n",
    "\n",
    "                G_loss       = G_loss.item()\n",
    "                t_force_loss = t_force_loss.item()\n",
    "            else:\n",
    "                G_loss       = float('nan')\n",
    "                t_force_loss = float('nan')\n",
    "            ft_b_loss = float('nan')\n",
    "            tf_b_loss = float('nan')\n",
    "\n",
    "        G_acc = (teacher_forcing_outputs.argmax(dim=-1) == targets).float().mean().item()\n",
    "\n",
    "        print(\"[Update {}]\".format(i))\n",
    "        print(\"Discriminator\")\n",
    "        print(\"=============\")\n",
    "        print(\"    Loss:\", D_loss)\n",
    "        print(\"    Acc:\", D_acc)\n",
    "        print(\"Generator\")\n",
    "        print(\"=============\")\n",
    "        print(\"    Loss:\", G_loss)\n",
    "        print(\"        Teacher-Force:\", t_force_loss)\n",
    "        print(\"        FreeToTeacher:\", ft_b_loss)\n",
    "        print(\"        TeacherToFree:\", tf_b_loss)\n",
    "        print(\"    Acc:\", G_acc)\n",
    "        print(\"####################################\")\n",
    "        print()\n",
    "        i += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            torch.save(generated_sequence.cpu().numpy(), \"professor_forcing_temp/{}.pth\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:11:50.213277Z",
     "start_time": "2019-08-03T23:11:50.164772Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'g': generator.state_dict(), 'd': discriminator.state_dict()}, 'professor_forcing_temp/GD_30000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:11:57.963380Z",
     "start_time": "2019-08-03T23:11:57.956399Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokens_to_intlist(tokens, token_to_key_dict):\n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "\n",
    "    patterns = []\n",
    "    intlist = []\n",
    "    last_pattern = tuple()\n",
    "\n",
    "    for token in tokens:\n",
    "        pattern = token_to_key_dict[token]\n",
    "        if pattern != tuple() and pattern[0] == \"<REPEAT>\":\n",
    "            for _ in range(pattern[1]):\n",
    "                patterns.append(last_pattern)\n",
    "        else:\n",
    "            patterns.append(pattern)\n",
    "            last_pattern = pattern\n",
    "\n",
    "    intlist.extend(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        intlist.append(0)\n",
    "        intlist.extend(pattern)\n",
    "    \n",
    "    return intlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:27:24.686053Z",
     "start_time": "2019-08-03T23:24:08.326083Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_sequence = tokens_to_intlist(free_running_generation(generator, inputs[:1], 50000, return_all_hiddens=False)[0][0].cpu().numpy(), ud_dataset.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T23:27:24.740480Z",
     "start_time": "2019-08-03T23:27:24.687813Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(np.array(generated_sequence), \"professor_forcing_temp/generated_sequence_chord.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
