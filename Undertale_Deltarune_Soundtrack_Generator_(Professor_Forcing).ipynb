{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undertale & Deltarune Soundtrack Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [**Table of Contents**](#Table-of-Contents)\n",
    "\n",
    "1. [**Imports**](#Imports)\n",
    "\n",
    "2. [**Data Processing**](#Data-Processing)\n",
    "\n",
    "    2.1 [Data Loading](#Data-Loading)\n",
    "    \n",
    "    2.2 [Data Preprocessing](#Data-Preprocessing)\n",
    "    \n",
    "    2.3 [Dataset & Dataloader Definition](#Dataset-&-Dataloader-Definition)\n",
    "    \n",
    "3. [**Model Definition**](#Model-Definition)\n",
    "    \n",
    "4. [**Hyperparameters & Instantiation**](#Hyperparameters-&-Instantiation)\n",
    "\n",
    "5. [**Training**](#Training)\n",
    "    \n",
    "    4.1 [Training Function](#Training-Function)\n",
    "    \n",
    "    4.2 [Training Session](#Training-Session)\n",
    "\n",
    "6. [**Loading the Best Model**](#Loading-the-Best-Model)\n",
    "\n",
    "7. [**Generation**](#Generation)\n",
    "    \n",
    "    6.1 [Sampling Function](#Sampling-Function)\n",
    "\n",
    "    6.2 [Generation Function](#Generation-Function)\n",
    "    \n",
    "    6.3 [Music Generation](#Music-Generation)\n",
    "\n",
    "8. [**Final Summary, Notes, and Thoughts**](#Final-Summary,-Notes,-and-Thoughts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:53.758653Z",
     "start_time": "2019-07-28T15:30:52.568832Z"
    }
   },
   "outputs": [],
   "source": [
    "import os                                         # File handling\n",
    "import itertools                                  # chain() for merging lists\n",
    "import random                                     # Shuffling\n",
    "import collections                                # Useful tools like Counter, OrderedDict\n",
    "import math                                       # For... math\n",
    "from decimal import Decimal                       # Scientific notations in string formatting\n",
    "from time import time                             # For use in progress bar\n",
    "\n",
    "import tqdm.auto as tqdm                          # Progress bar\n",
    "\n",
    "import torch                                      # Deep Learning Framework\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt                   # Plotting training progress\n",
    "from matplotlib.ticker import AutoLocator\n",
    "%matplotlib inline\n",
    "\n",
    "fig_bg_color = \"lightsteelblue\"\n",
    "plot_bg_color = \"slategray\"\n",
    "fontsize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T06:55:43.051798Z",
     "start_time": "2019-03-17T06:55:43.046023Z"
    }
   },
   "source": [
    "## Data Processing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Read the text files in the target directory.\n",
    "\n",
    "Do some processing to make sure the texts are clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:54.627371Z",
     "start_time": "2019-07-28T15:30:53.761646Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANOTHER_HIM_-_DeltaRune.txt', '42 46 49 53 0 42 46 '),\n",
       " ('A_Town_Called_Hometown_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '73 89 0 73 89 0 73 8'),\n",
       " ('Basement_Deltarune_-_Arranged_for_Piano.txt', '39 51 0 39 51 0 39 5'),\n",
       " ('Before_the_Story_Deltarune_-_Arranged_for_piano_.txt',\n",
       "  '48 0 48 0 48 0 48 0 '),\n",
       " ('Card_Castle_Deltarune_-_Arranged_for_Piano.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Checker_Dance_Deltarune_-_Arranged_for_Piano.txt', '30 0 30 0 30 0 30 0 '),\n",
       " ('Deltarune_-_Beginning.txt', '48 55 0 48 55 0 48 5'),\n",
       " ('Deltarune_-_Chaos_King.txt', '27 39 0 27 39 0 27 3'),\n",
       " ('Deltarune_-_Darkness_Falls.txt', '61 64 71 75 0 61 64 '),\n",
       " ('Deltarune_-_Dont_Forget_Ending_Theme_Solo_Piano_Version.txt',\n",
       "  '77 0 77 0 77 0 77 0 '),\n",
       " ('Deltarune_-_Friendship.txt', '74 0 74 0 74 0 74 0 '),\n",
       " ('Deltarune_-_Gallery.txt', '32 36 39 68 0 32 36 '),\n",
       " ('Deltarune_-_Lancer_Battle.txt', '62 0 62 0 62 0 0 0 0'),\n",
       " ('DELTARUNE_-_Lancer_piano_solo.txt', '0 0 0 62 0 62 0 62 0'),\n",
       " ('Deltarune_-_Lantern.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Deltarune_-_Rude_Buster_Playable.txt', '31 43 0 31 43 0 31 4'),\n",
       " ('Deltarune_-_The_Chase.txt', '24 31 0 24 31 0 24 3'),\n",
       " ('Deltarune_-_THE_WORLD_REVOLVING.txt', '45 57 0 45 57 0 45 5'),\n",
       " ('Deltarune_-_Thrash_Machine.txt', '39 0 39 0 39 0 39 0 '),\n",
       " ('Deltarune_-_You_Can_Always_Come_Home.txt', '46 0 46 0 46 0 46 0 '),\n",
       " ('Deltarune_Legend.txt', '0 0 0 0 0 0 0 0 0 0 '),\n",
       " ('Empty_Town_Deltarune_-_Arranged_for_Piano.txt', '58 70 0 58 70 0 58 7'),\n",
       " ('Fanfare_Deltarune_-_Arranged_for_Piano.txt', '37 49 0 37 49 0 37 4'),\n",
       " ('Hip_Shop_Deltarune_-_Arranged_for_Piano.txt', '44 68 0 44 68 0 44 6'),\n",
       " ('Im_Very_Bad_Deltarune_-_Arranged_for_Piano.txt', '67 0 67 0 67 0 67 0 '),\n",
       " ('Man_Deltarune.txt', '61 0 61 0 61 0 61 0 '),\n",
       " ('Quiet_Autumn_Deltarune_-_Arranged_for_Piano.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Rouxls_Kaard.txt', '43 74 0 43 74 0 43 7'),\n",
       " ('Scarlet_Forest_-_Deltarune_Advanced_Piano.txt', '55 0 55 0 55 0 55 0 '),\n",
       " ('School_-_DeltaRune.txt', '38 66 0 38 66 0 38 6'),\n",
       " ('Susie_Deltarune_-_Arranged_for_Piano.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('The_Circus_Deltarune_-_Arranged_for_Piano.txt', '54 0 54 0 54 0 54 0 '),\n",
       " ('The_Door_Deltarune_-_Arranged_for_Piano.txt', '49 80 0 49 80 0 49 8'),\n",
       " ('The_Field_of_Hopes_and_Dreams_Deltarune_-_Arranged_for_Piano.txt',\n",
       "  '56 68 71 78 0 56 68 '),\n",
       " ('THE_HOLY_Deltarune_-_Arranged_for_Piano.txt', '39 61 65 0 39 61 65 '),\n",
       " ('Undertale_-_004_Fallen_Down__085_Fallen_Down_Reprise.txt',\n",
       "  '63 79 0 63 79 0 63 7'),\n",
       " ('Undertale_-_005_Ruins.txt', '57 0 57 0 57 0 57 0 '),\n",
       " ('Undertale_-_010_Ghost_Fight.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_011_Determination.txt', '40 79 0 40 79 0 40 7'),\n",
       " ('Undertale_-_031_Waterfall.txt', '65 0 65 0 65 0 65 0 '),\n",
       " ('Undertale_-_036_Dummy.txt', '65 68 0 65 68 0 65 6'),\n",
       " ('Undertale_-_043_Temmie_Village.txt', '49 0 49 0 49 0 49 0 '),\n",
       " ('Undertale_-_046_Spear_of_Justice.txt', '32 44 68 75 80 0 32 '),\n",
       " ('Undertale_-_048_Alphys.txt', '47 0 47 0 47 0 47 0 '),\n",
       " ('Undertale_-_050_Metal_Crusher.txt', '64 0 64 0 64 0 64 0 '),\n",
       " ('Undertale_-_051_Another_Medium.txt', '85 0 85 0 85 0 85 0 '),\n",
       " ('Undertale_-_053_Stronger_Monsters.txt', '35 0 35 0 35 0 35 0 '),\n",
       " ('Undertale_-_063_Its_Raining_Somewhere_Else.txt', '49 0 49 0 49 52 0 49'),\n",
       " ('Undertale_-_065_CORE.txt', '69 72 74 0 69 72 74 '),\n",
       " ('Undertale_-_068_Death_by_Glamour.txt', '41 0 41 0 41 0 41 0 '),\n",
       " ('Undertale_-_079_Your_Best_Nightmare.txt', '35 47 58 70 0 35 47 '),\n",
       " ('Undertale_-_080_Finale.txt', '47 54 69 0 47 54 69 '),\n",
       " ('Undertale_-_100_MEGALOVANIA.txt', '63 0 63 0 63 0 63 0 '),\n",
       " ('Undertale_-_ASGORE.txt', '50 57 65 0 50 57 65 '),\n",
       " ('Undertale_-_Battle_Against_a_True_Hero.txt', '88 0 88 0 88 0 88 0 '),\n",
       " ('Undertale_-_Bonetrousle.txt', '37 0 37 0 37 0 37 0 '),\n",
       " ('Undertale_-_Heartache.txt', '31 47 0 31 47 0 31 4'),\n",
       " ('Undertale_-_Hopes_and_Dreams.txt', '64 78 0 64 78 0 64 7'),\n",
       " ('Undertale_-_Memory.txt', '77 0 77 0 77 0 77 0 '),\n",
       " ('Undertale_-_sans.txt', '33 0 33 0 33 0 33 0 '),\n",
       " ('Undertale_-_SAVE_the_World.txt', '45 57 67 0 45 57 67 '),\n",
       " ('Undertale_-_Spider_Dance.txt', '42 73 78 0 42 73 78 '),\n",
       " ('Undertale_Undertale_Piano.txt', '59 0 59 0 59 0 59 0 '),\n",
       " ('Vs._Susie_Deltarune_-_Arranged_for_Piano.txt', '47 0 47 0 47 0 47 0 ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(texts_dir):\n",
    "\n",
    "    if not os.path.isdir(texts_dir):\n",
    "        raise FileNotFoundError(\"given text directory not found: {}\".format(texts_dir))\n",
    "\n",
    "    texts = []\n",
    "    \n",
    "    for text_path in (file.path for file in os.scandir(texts_dir) if file.is_file() and file.name.endswith(\".txt\")):\n",
    "        with open(file=text_path, mode='r', encoding=\"utf-8\") as text_file:\n",
    "            \n",
    "            text = text_file.read().strip()\n",
    "\n",
    "            if not text.replace(' ', '').isdigit():\n",
    "                raise RuntimeError(\"one or more characters other than digits and white spaces are detected: {}\".format(text_path))\n",
    "\n",
    "            while \"  \" in text:\n",
    "                text = text.replace(\"  \", ' ')\n",
    "            \n",
    "            texts.append((text_path, text))\n",
    "    \n",
    "    return dict(texts)\n",
    "\n",
    "\n",
    "[(os.path.split(text_path)[1], text[:20]) for text_path, text in get_texts(\"./source/converted_texts\").items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get integers out of the text and make lists of ints.\n",
    "\n",
    "These lists can be used for the input of the models, or be further processed to compress or simplify the sequences.\n",
    "\n",
    "In this notebook, I'll leave the data as it is and do note-by-note. (Similar to Character-By-Character approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:55.103584Z",
     "start_time": "2019-07-28T15:30:54.629324Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 46, 49, 53, 0, 42, 46, 49, 53, 0], [73, 89, 0, 73, 89, 0, 73, 89, 0, 73], [39, 51, 0, 39, 51, 0, 39, 51, 0, 39], [48, 0, 48, 0, 48, 0, 48, 0, 48, 0], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [30, 0, 30, 0, 30, 0, 30, 0, 30, 0], [48, 55, 0, 48, 55, 0, 48, 55, 0, 48], [27, 39, 0, 27, 39, 0, 27, 39, 0, 27], [61, 64, 71, 75, 0, 61, 64, 71, 75, 0], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [74, 0, 74, 0, 74, 0, 74, 0, 74, 0], [32, 36, 39, 68, 0, 32, 36, 39, 68, 0], [62, 0, 62, 0, 62, 0, 0, 0, 0, 65], [0, 0, 0, 62, 0, 62, 0, 62, 0, 62], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [31, 43, 0, 31, 43, 0, 31, 43, 0, 31], [24, 31, 0, 24, 31, 0, 24, 31, 0, 24], [45, 57, 0, 45, 57, 0, 45, 57, 0, 45], [39, 0, 39, 0, 39, 0, 39, 0, 39, 0], [46, 0, 46, 0, 46, 0, 46, 0, 46, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [58, 70, 0, 58, 70, 0, 58, 70, 0, 58], [37, 49, 0, 37, 49, 0, 37, 49, 0, 37], [44, 68, 0, 44, 68, 0, 44, 68, 0, 44], [67, 0, 67, 0, 67, 0, 67, 0, 67, 0], [61, 0, 61, 0, 61, 0, 61, 0, 61, 0], [49, 0, 49, 0, 49, 0, 49, 0, 54, 0], [43, 74, 0, 43, 74, 0, 43, 74, 0, 43], [55, 0, 55, 0, 55, 0, 55, 0, 55, 0], [38, 66, 0, 38, 66, 0, 38, 66, 0, 38], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [54, 0, 54, 0, 54, 0, 54, 0, 54, 0], [49, 80, 0, 49, 80, 0, 49, 80, 0, 49], [56, 68, 71, 78, 0, 56, 68, 71, 78, 0], [39, 61, 65, 0, 39, 61, 65, 0, 39, 61], [63, 79, 0, 63, 79, 0, 63, 79, 0, 63], [57, 0, 57, 0, 57, 0, 57, 0, 57, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [40, 79, 0, 40, 79, 0, 40, 79, 0, 40], [65, 0, 65, 0, 65, 0, 65, 0, 65, 0], [65, 68, 0, 65, 68, 0, 65, 68, 0, 65], [49, 0, 49, 0, 49, 0, 49, 0, 49, 0], [32, 44, 68, 75, 80, 0, 32, 44, 68, 75], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0], [64, 0, 64, 0, 64, 0, 64, 0, 64, 0], [85, 0, 85, 0, 85, 0, 85, 0, 80, 0], [35, 0, 35, 0, 35, 0, 35, 0, 35, 0], [49, 0, 49, 0, 49, 52, 0, 49, 52, 56], [69, 72, 74, 0, 69, 72, 74, 0, 69, 72], [41, 0, 41, 0, 41, 0, 41, 0, 41, 0], [35, 47, 58, 70, 0, 35, 47, 58, 70, 0], [47, 54, 69, 0, 47, 54, 69, 0, 47, 54], [63, 0, 63, 0, 63, 0, 63, 0, 0, 63], [50, 57, 65, 0, 50, 57, 65, 0, 50, 57], [88, 0, 88, 0, 88, 0, 88, 0, 88, 0], [37, 0, 37, 0, 37, 0, 37, 0, 37, 0], [31, 47, 0, 31, 47, 0, 31, 47, 0, 31], [64, 78, 0, 64, 78, 0, 64, 78, 0, 64], [77, 0, 77, 0, 77, 0, 77, 0, 77, 0], [33, 0, 33, 0, 33, 0, 33, 0, 33, 0], [45, 57, 67, 0, 45, 57, 67, 0, 45, 57], [42, 73, 78, 0, 42, 73, 78, 0, 73, 78], [59, 0, 59, 0, 59, 0, 59, 0, 59, 0], [47, 0, 47, 0, 47, 0, 47, 0, 47, 0]]\n"
     ]
    }
   ],
   "source": [
    "def texts_to_intlists(text_list):\n",
    "    \n",
    "    intlists = []\n",
    "    \n",
    "    for i, text in enumerate(iterable=text_list):\n",
    "        \n",
    "        int_strings = text.split(' ')\n",
    "        \n",
    "        if not all(int_str.isdigit() for int_str in int_strings):\n",
    "            raise RuntimeError(\"non-digit string detected in text {}\".format(i))\n",
    "\n",
    "        ints = [int(int_str) for int_str in int_strings]\n",
    "        \n",
    "        intlists.append(ints)\n",
    "        \n",
    "    return intlists\n",
    "\n",
    "\n",
    "print([ints[:10] for ints in texts_to_intlists(get_texts(\"./source/converted_texts\").values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset class from which training data can be sampled.\n",
    "\n",
    "This Dataset should convert the encoded sequence above into tensors\n",
    "\n",
    "and have a method for shuffling the order of multiple sequences while\n",
    "\n",
    "leaving the patterns inside of each sequence untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:55.113558Z",
     "start_time": "2019-07-28T15:30:55.106576Z"
    }
   },
   "outputs": [],
   "source": [
    "class UndertaleDeltaruneDataset(Dataset):\n",
    "    def __init__(self, texts_dir, batch_size=1, max_repeats=15):\n",
    "        self.texts = get_texts(texts_dir) # read and get a dictionary of {file_paths: text_contents}\n",
    "        self.sequences = texts_to_intlists(self.texts.values())\n",
    "\n",
    "        self.texts_dir = texts_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def data_len(self):\n",
    "        return sum([len(sequence) for sequence in self.sequences])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        shuffled_list = list(itertools.chain(*random.sample(self.sequences, len(self.sequences))))\n",
    "        inputs = torch.LongTensor(shuffled_list[:-1])\n",
    "        labels = torch.LongTensor(shuffled_list[1:])\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom class that loads the data from the dataset above and\n",
    "\n",
    "allows iteration over the dataset, yielding a small sequence batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:55.130021Z",
     "start_time": "2019-07-28T15:30:55.114554Z"
    }
   },
   "outputs": [],
   "source": [
    "class UDBatchLoader:\n",
    "    def __init__(self, ud_dataset, batch_size, sequence_len, drop_last=False, batch_first=True):\n",
    "        self.ud_dataset = ud_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_len = sequence_len\n",
    "        self.drop_last = drop_last\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return math.floor((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "        return math.ceil((self.ud_dataset.data_len() - 1) / self.sequence_len)\n",
    "    \n",
    "    def generator(self):\n",
    "        seq_len = self.sequence_len\n",
    "        n_seq_batches = self.__len__()\n",
    "        batch_first = self.batch_first\n",
    "        \n",
    "        input_batch, target_batch = next(iter(DataLoader(self.ud_dataset, self.batch_size)))\n",
    "        if not batch_first:\n",
    "            input_batch = input_batch.transpose(0, 1).contiguous()\n",
    "            target_batch = target_batch.transpose(0, 1).contiguous()\n",
    "        \n",
    "        for start, end in zip(range(0, seq_len * n_seq_batches, seq_len), range(seq_len, (seq_len + 1) * n_seq_batches, seq_len)):\n",
    "            if batch_first:\n",
    "                yield (input_batch[:, start:end].contiguous(), target_batch[:, start:end].contiguous())\n",
    "            else:\n",
    "                yield (input_batch[start:end], target_batch[start:end])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Define the model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:55.390324Z",
     "start_time": "2019-07-28T15:30:55.372397Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_hidden0 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "        self.init_hidden1 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "        self.init_hidden2 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=129, embedding_dim=64)\n",
    "\n",
    "        self.norm0 = nn.LayerNorm(64)\n",
    "        self.gru0  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(64)\n",
    "        self.gru1  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(64)\n",
    "        self.gru2  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.LayerNorm(64),\n",
    "            nn.Linear(in_features=64, out_features=128)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=129)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hiddens, return_all_hiddens=False):\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens = []\n",
    "\n",
    "        x = self.embed(x)\n",
    "\n",
    "        x, new_hidden0 = self.gru0(self.norm0(x, hiddens[0]))\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "        x, new_hidden1 = self.gru1(self.norm1(x, hiddens[1]))\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "        x, new_hidden2 = self.gru2(self.norm2(x, hiddens[2]))\n",
    "        if return_all_hiddens:\n",
    "            internal_hiddens.append(x)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if return_all_hiddens:\n",
    "            return x, [new_hidden0, new_hidden1, new_hidden2], internal_hiddens\n",
    "        return x, [new_hidden0, new_hidden1, new_hidden2]\n",
    "\n",
    "    def get_init_hiddens(self, n_batches):\n",
    "        return [self.init_hidden0.repeat(1, n_batches, 1),\n",
    "                self.init_hidden1.repeat(1, n_batches, 1),\n",
    "                self.init_hidden2.repeat(1, n_batches, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:56.155187Z",
     "start_time": "2019-07-28T15:30:56.143205Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.init_hidden0 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "        self.init_hidden1 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "        self.init_hidden2 = nn.Parameter(torch.randn(1, 1, 64))\n",
    "\n",
    "        self.norm0 = nn.LayerNorm(64)\n",
    "        self.gru0  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(64)\n",
    "        self.gru1  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(64)\n",
    "        self.gru2  = nn.GRU(input_size=64, hidden_size=64, batch_first=True)\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.LayerNorm(64),\n",
    "            nn.Linear(in_features=64, out_features=128)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hiddens):\n",
    "        x, new_hidden0 = self.gru0(self.norm0(x, hiddens[0]))\n",
    "        x, new_hidden1 = self.gru1(self.norm1(x, hiddens[1]))\n",
    "        x, new_hidden2 = self.gru2(self.norm2(x, hiddens[2]))\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, [new_hidden0, new_hidden1, new_hidden2]\n",
    "\n",
    "    def get_init_hiddens(self, n_batches):\n",
    "        return [self.init_hidden0.repeat(1, n_batches, 1),\n",
    "                self.init_hidden1.repeat(1, n_batches, 1),\n",
    "                self.init_hidden2.repeat(1, n_batches, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:30:59.362569Z",
     "start_time": "2019-07-28T15:30:59.354591Z"
    }
   },
   "outputs": [],
   "source": [
    "def free_running_generation(generator, inputs, seq_len, return_all_hiddens=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    generator (Generator): the generator model\n",
    "    inputs (LongTensor): 3D tensor with dimensions [n_batches, 1, input_dim]\n",
    "    seq_len (int): length of sequence to generate\n",
    "    return_all_hiddens (bool, optional): whether to retrieve the internal hidden states\n",
    "                                         for all timesteps from every RNN layer (default: False)\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    output_sequence (LongTensor): tensor of generated outputs\n",
    "    internal_hiddens (list[Tensor]): list of tensors containing internal hidden states\n",
    "                                     for all timesteps from every RNN layer. Returned only\n",
    "                                     if `return_all_hiddens` is True\n",
    "    \"\"\"\n",
    "    output_sequence = []\n",
    "    if return_all_hiddens:\n",
    "        internal_hiddens = []\n",
    "\n",
    "    hiddens = generator.get_init_hiddens(inputs.size(0))\n",
    "    x = inputs[:, -1:]\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        if return_all_hiddens:\n",
    "            y, hiddens, current_internal_hiddens = generator(x, hiddens, return_all_hiddens=True)\n",
    "            internal_hiddens.append(current_internal_hiddens)\n",
    "        else:\n",
    "            y, hiddens = generator(x, hiddens, return_all_hiddens=False)\n",
    "        y = torch.multinomial(y.softmax(dim=-1), num_samples=1)\n",
    "        output_sequence.append(y)\n",
    "        x = y\n",
    "    output_sequence = torch.cat(output_sequence, dim=1)\n",
    "    \n",
    "    if return_all_hiddens:\n",
    "        internal_hiddens = [torch.cat(layer_hiddens, dim=1) for layer_hiddens in zip(*internal_hiddens)]\n",
    "        return output_sequence, internal_hiddens\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator, b_seq_teacher, b_seq_free, return_acc=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    discriminator (Discriminator): the Discriminator model.\n",
    "    b_seq_teacher (Tensor): behavior sequence from generator during teacher-forcing mode.\n",
    "                            Must have dimensions [n_batches, seq_len, behavior_size].\n",
    "    b_seq_free (Tensor): behavior sequence from generator during free-running mode.\n",
    "                         Assumed to have the same dimensionality as `b_seq_teacher`.\n",
    "    return_acc (bool): whether to return the discriminator accuracy or not. (default: False)\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    discriminator_loss (Tensor): the discriminator loss as a scalar tensor.\n",
    "    \"\"\"\n",
    "    ### Ensure that gradients will flow only through the discriminator and not the generator\n",
    "    b_seq_teacher = b_seq_teacher.detach()\n",
    "    b_seq_free    = b_seq_free.detach()\n",
    "\n",
    "    inputs  = torch.cat([b_seq_teacher, b_seq_free], dim=0)\n",
    "    targets = torch.cat([b_seq_teacher.new_ones(b_seq_teacher.size(0), 1),\n",
    "                         b_seq_free.new_zeros(b_seq_free.size(0), 1)], dim=0)\n",
    "\n",
    "    hiddens = discriminator.get_init_hiddens(n_batches=inputs.size(0))\n",
    "    raw_preds, _ = discriminator(inputs, hiddens)\n",
    "\n",
    "    if return_acc:\n",
    "        preds = raw_preds.sigmoid()\n",
    "\n",
    "        discriminator_loss = F.binary_cross_entropy(preds, targets)\n",
    "        discriminator_acc  = (preds.gt(0.5) == targets.byte()).float().mean().item()\n",
    "\n",
    "        return discriminator_loss, discriminator_acc\n",
    "\n",
    "    else:\n",
    "        discriminator_loss = F.binary_cross_entropy_with_logits(raw_preds, targets)\n",
    "\n",
    "        return discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator     = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator_optimizer     = optim.Adam(generator.parameters(), lr=3e-3)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=3e-3)\n",
    "\n",
    "n_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T02:53:33.407797Z",
     "start_time": "2019-03-23T02:53:33.367000Z"
    },
    "code_folding": [
     22,
     33
    ]
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, n_epochs, device, train_loader, lr_scheduler=None, prehistory=None, checkpoint_dir='.', checkpoint_basename=None, save_every=None):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    =======\n",
    "    model (torch module): model to train.\n",
    "    optimizer (torch optimizer): optimizer to use for training the model.\n",
    "    criterion (torch loss module): loss function for computing loss.\n",
    "    n_epochs (int): number of epochs to train.\n",
    "    device (str): device on which the training happens.\n",
    "    train_loader (iterable): training data(inputs, labels) loader.\n",
    "    lr_scheduler (lr_scheduler, optional): learning rate scheduler.\n",
    "    prehistory (dict, optional): can be provided for plotting when continuing\n",
    "                                 the training.\n",
    "    checkpoint_dir (str, optional): the directory in which checkpoint files are saved.\n",
    "                               (default: '.')\n",
    "    checkpoint_basename (str, optional): base name for checkpoint files (default: None)\n",
    "    save_every (int, optional): how often to create mid-training checkpoints, separate\n",
    "                                from the best checkpoint. Final result is always saved\n",
    "                                unless the base name is not given.\n",
    "                                (default: None)\n",
    "    \"\"\"\n",
    "    if prehistory:\n",
    "        history         = prehistory\n",
    "        best_loss_idx   = history['loss'].index(min(history['loss']))\n",
    "        best_loss       = history['loss'][best_loss_idx]\n",
    "        best_loss_epoch = history['epoch'][best_loss_idx]\n",
    "        best_loss_acc_1 = history['acc_1'][best_loss_idx]\n",
    "        best_loss_acc_5 = history['acc_5'][best_loss_idx]\n",
    "        loss_avg = loss = history['loss'][-1]\n",
    "        acc_1           = history['acc_1'][-1]\n",
    "        acc_5           = history['acc_5'][-1]\n",
    "        i_epoch         = history['epoch'][-1] + 1\n",
    "    else:\n",
    "        history         = {'epoch':[], 'loss': [], 'acc_1': [], 'acc_5': []}\n",
    "        best_loss       = float('inf')\n",
    "        best_loss_epoch = -1\n",
    "        best_loss_acc_1 = 0.\n",
    "        best_loss_acc_5 = 0.\n",
    "        loss_avg = loss = float('inf')\n",
    "        acc_1           = 0.\n",
    "        acc_5           = 0.\n",
    "        i_epoch         = 0\n",
    "    \n",
    "    if save_every is None:\n",
    "        save_every = n_epochs\n",
    "    _save_every_check = save_every - 1\n",
    "    if checkpoint_basename:\n",
    "        checkpoint_normal_filepath_template = os.path.join(checkpoint_dir, checkpoint_basename + \"(epoch={}).pth\")\n",
    "        checkpoint_best_filepath   = os.path.join(checkpoint_dir, checkpoint_basename + \"_best.pth\")\n",
    "    \n",
    "    def update_progress_stats(update_epoch, update_train):\n",
    "        if update_epoch:\n",
    "            if 'momentum' in optimizer.param_groups[0]:\n",
    "                momentum = optimizer.param_groups[0]['momentum']\n",
    "            elif 'betas' in optimizer.param_groups[0]:\n",
    "                momentum = optimizer.param_groups[0]['betas'][0]\n",
    "            else:\n",
    "                momentum = None\n",
    "            epoch_iterator.set_postfix_str(\"current_epoch={}, \"\n",
    "                                           \"loss={:.4f}, acc=(top1={:.4f}, top5={:.4f}), \"\n",
    "                                           \"best_loss_stats(epoch={}, loss={:.4f}, acc(top1={:.4f}, top5={:.4f})), \"\n",
    "                                           \"lr={:.4e}, momentum={:.4f}\"\n",
    "                                           .format(epoch,\n",
    "                                                   loss_avg, acc_1, acc_5,\n",
    "                                                   best_loss_epoch, best_loss, best_loss_acc_1, best_loss_acc_5,\n",
    "                                                   Decimal(optimizer.param_groups[0]['lr']),\n",
    "                                                   momentum),\n",
    "                                           refresh=True)\n",
    "        if update_train:\n",
    "            train_progress_bar.set_postfix_str(\"loss={:>7.4f}, acc(top1={:.4f}, top5={:.4f})\".format(loss.item(), b_acc_1, b_acc_5), refresh=True)\n",
    "    \n",
    "    tracking_dict = {'history':         history,\n",
    "                     'hyperparameters': hyperparameters,\n",
    "                     'model_dict':      model.state_dict(),\n",
    "                     'optimizer_dict':  optimizer.state_dict(),\n",
    "                     'lr_dict':         lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "                     'tokens':          ud_dataset.tokens}\n",
    "    \n",
    "    if n_epochs < 1:\n",
    "        return history\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    plot_on = False\n",
    "    \n",
    "    if lr_scheduler:\n",
    "        last_epoch = int(lr_scheduler.last_epoch)\n",
    "    \n",
    "    try:\n",
    "        epoch_iterator = tqdm.tqdm(iterable=range(i_epoch, i_epoch + n_epochs), desc=\"Train Epochs\")\n",
    "        train_progress_bar = tqdm.tqdm(total=len(train_loader), desc=\"Train Iterations\")\n",
    "        model.train()\n",
    "        for epoch in epoch_iterator:\n",
    "            if lr_scheduler:\n",
    "                last_epoch += 1\n",
    "            \n",
    "            train_progress_bar.n = 0\n",
    "            train_progress_bar.last_print_n = 0\n",
    "            train_progress_bar.start_t = time()\n",
    "            train_progress_bar.last_print_t = time()\n",
    "            train_progress_bar.refresh()\n",
    "            \n",
    "            update_progress_stats(True, False)\n",
    "\n",
    "            hidden_states = model.init_hidden(train_loader.batch_size)\n",
    "\n",
    "            running_loss = 0\n",
    "            n_top1_corrects = 0\n",
    "            n_top5_corrects = 0\n",
    "            n_instances = 0\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                if lr_scheduler:\n",
    "                    lr_scheduler.step(last_epoch + (i / len(train_loader)))\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.view(-1).to(device)\n",
    "\n",
    "                outputs, hidden_states = model(inputs, hidden_states)\n",
    "                outputs = outputs.view(-1, outputs.size(-1))\n",
    "                \n",
    "                hidden_states = ([hidden.detach() for hidden in hidden_states[0]],\n",
    "                                 [cell.detach() for cell in hidden_states[1]])\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss    += loss.item() * labels.size(0)\n",
    "                top5_match       = outputs.data.topk(k=5, dim=1)[1].eq(labels.unsqueeze(1))\n",
    "                top1_corrects    = top5_match[:, 0].sum().item()\n",
    "                top5_corrects    = top5_match.sum().item()\n",
    "                b_acc_1          = top1_corrects / labels.size(0)\n",
    "                b_acc_5          = top5_corrects / labels.size(0)\n",
    "                n_top1_corrects += top1_corrects\n",
    "                n_top5_corrects += top5_corrects\n",
    "                n_instances     += labels.size(0)\n",
    "                \n",
    "                update_progress_stats(True, True)\n",
    "                del outputs, loss, top5_match, top1_corrects, top5_corrects, b_acc_1, b_acc_5\n",
    "                train_progress_bar.update(1)\n",
    "                \n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.last_epoch = last_epoch\n",
    "            loss_avg = running_loss / n_instances\n",
    "            acc_1    = n_top1_corrects / n_instances\n",
    "            acc_5    = n_top5_corrects / n_instances\n",
    "            del running_loss, n_top1_corrects, n_top5_corrects, n_instances\n",
    "            \n",
    "            update_progress_stats(True, False)\n",
    "            \n",
    "            history['epoch'].append(epoch)\n",
    "            history['loss'].append(loss_avg)\n",
    "            history['acc_1'].append(acc_1)\n",
    "            history['acc_5'].append(acc_5)\n",
    "            if loss_avg < best_loss:\n",
    "                best_loss = loss_avg\n",
    "                best_loss_epoch = epoch\n",
    "                best_loss_acc_1 = acc_1\n",
    "                best_loss_acc_5 = acc_5\n",
    "                if checkpoint_basename:\n",
    "                    torch.save(tracking_dict, checkpoint_best_filepath)\n",
    "            \n",
    "            if checkpoint_basename and ((epoch - i_epoch) % save_every == _save_every_check or (epoch - i_epoch) == (n_epochs - 1)):\n",
    "                torch.save(tracking_dict, checkpoint_normal_filepath_template.format(epoch))\n",
    "                \n",
    "            if epoch >= 1:\n",
    "                if not plot_on:\n",
    "                    %matplotlib notebook\n",
    "                    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 12), facecolor=fig_bg_color)\n",
    "                    axes[0].set_facecolor(plot_bg_color)\n",
    "                    axes[0].grid(True)\n",
    "                    axes[0].set_title(\"Training Loss\", fontsize=fontsize)\n",
    "                    axes[0].set_xlabel(\"Epoch\", fontsize=fontsize)\n",
    "                    axes[0].set_ylabel(\"Loss\", fontsize=fontsize)\n",
    "                    axes[0].plot([], [], color='blue', label='loss')\n",
    "                    axes[0].legend()\n",
    "                    axes[1].set_facecolor(plot_bg_color)\n",
    "                    axes[1].grid(True)\n",
    "                    axes[1].set_title(\"Training Accuracy\", fontsize=fontsize)\n",
    "                    axes[1].set_xlabel(\"Epoch\", fontsize=fontsize)\n",
    "                    axes[1].set_ylabel(\"Accuracy\", fontsize=fontsize)\n",
    "                    axes[1].plot([], [], color='blue', label='top-1 acc')\n",
    "                    axes[1].plot([], [], color='orange', label='top-5 acc')\n",
    "                    axes[1].legend()\n",
    "                    fig.canvas.draw()\n",
    "                    plot_on = True\n",
    "                    \n",
    "                axes[0].lines[0].set_xdata(history['epoch'])\n",
    "                axes[0].lines[0].set_ydata(history['loss'])\n",
    "                axes[1].lines[0].set_xdata(history['epoch'])\n",
    "                axes[1].lines[0].set_ydata(history['acc_1'])\n",
    "                axes[1].lines[1].set_xdata(history['epoch'])\n",
    "                axes[1].lines[1].set_ydata(history['acc_5'])\n",
    "\n",
    "                axes[0].set_xlim(-0.05 * epoch, 1.05 * epoch)\n",
    "                max_min_diff = max(history['loss']) - min(history['loss'])\n",
    "                if max_min_diff > 0:\n",
    "                    axes[0].set_ylim(min(history['loss']) - 0.05 * max_min_diff, max(history['loss']) + 0.05 * max_min_diff)\n",
    "                axes[1].set_xlim(-0.05 * epoch, 1.05 * epoch)\n",
    "                max_min_diff = max(history['acc_1'] + history['acc_5']) - min(history['acc_1'] + history['acc_5'])\n",
    "                if max_min_diff > 0:\n",
    "                    axes[1].set_ylim(min(history['acc_1'] + history['acc_5']) - 0.05 * max_min_diff, max(history['acc_1'] + history['acc_5']) + 0.05 * max_min_diff)\n",
    "\n",
    "                axes[0].xaxis.set_major_locator(AutoLocator())\n",
    "                axes[0].yaxis.set_major_locator(AutoLocator())\n",
    "                axes[1].xaxis.set_major_locator(AutoLocator())\n",
    "                axes[1].yaxis.set_major_locator(AutoLocator())\n",
    "\n",
    "                xlim = axes[0].get_xlim()\n",
    "                xticks = [tick for tick in axes[0].get_xticks() if xlim[0] <= tick <= xlim[1]]\n",
    "                index = len(history['loss']) - 1 - history['loss'][::-1].index(max(history['loss']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                index = len(history['loss']) - 1 - history['loss'][::-1].index(min(history['loss']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                if epoch not in xticks:\n",
    "                    xticks.append(epoch)\n",
    "                axes[0].set_xticks(xticks)\n",
    "\n",
    "                xlim = axes[1].get_xlim()\n",
    "                xticks = [tick for tick in axes[1].get_xticks() if xlim[0] <= tick <= xlim[1]]\n",
    "                index = len(history['acc_1']) - 1 - history['acc_1'][::-1].index(max(history['acc_1']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                index = len(history['acc_1']) - 1 - history['acc_1'][::-1].index(min(history['acc_1']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                index = len(history['acc_5']) - 1 - history['acc_5'][::-1].index(max(history['acc_5']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                index = len(history['acc_5']) - 1 - history['acc_5'][::-1].index(min(history['acc_5']))\n",
    "                if index not in xticks:\n",
    "                    xticks.append(index)\n",
    "                if epoch not in xticks:\n",
    "                    xticks.append(epoch)\n",
    "                axes[1].set_xticks(xticks)\n",
    "\n",
    "                ylim = axes[0].get_ylim()\n",
    "                yticks = [tick for tick in axes[0].get_yticks() if ylim[0] <= tick <= ylim[1]]\n",
    "                if max(history['loss']) not in yticks:\n",
    "                    yticks.append(max(history['loss']))\n",
    "                if best_loss not in yticks:\n",
    "                    yticks.append(best_loss)\n",
    "                if history['loss'][-1] not in yticks:\n",
    "                    yticks.append(history['loss'][-1])\n",
    "                axes[0].set_yticks(yticks)\n",
    "\n",
    "                ylim = axes[1].get_ylim()\n",
    "                yticks = [tick for tick in axes[1].get_yticks() if ylim[0] <= tick <= ylim[1]]\n",
    "                if max(history['acc_1']) not in yticks:\n",
    "                    yticks.append(max(history['acc_1']))\n",
    "                if min(history['acc_1']) not in yticks:\n",
    "                    yticks.append(min(history['acc_1']))\n",
    "                if history['acc_1'][-1] not in yticks:\n",
    "                    yticks.append(history['acc_1'][-1])\n",
    "                if max(history['acc_5']) not in yticks:\n",
    "                    yticks.append(max(history['acc_5']))\n",
    "                if min(history['acc_5']) not in yticks:\n",
    "                    yticks.append(min(history['acc_5']))\n",
    "                if history['acc_5'][-1] not in yticks:\n",
    "                    yticks.append(history['acc_5'][-1])\n",
    "                axes[1].set_yticks(yticks)\n",
    "\n",
    "                fig.canvas.draw()\n",
    "                plt.pause(0.001)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step(int(last_epoch))\n",
    "    %matplotlib inline\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters & Instantiation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)\n",
    "\n",
    "Set hyperparameters and instantiate a dataset, model, optimizer, and criterion. (+ optionally a LR scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T02:53:26.387150Z",
     "start_time": "2019-03-23T02:53:22.732019Z"
    }
   },
   "outputs": [],
   "source": [
    "seed                   = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "batch_size             = 8\n",
    "max_repeats            = 20\n",
    "sequence_length        = 300\n",
    "\n",
    "embedding_dim          = 16\n",
    "hidden_dim             = 256\n",
    "n_lstm_layers          = 3\n",
    "dropout                = 0.3\n",
    "\n",
    "n_epochs               = 1000\n",
    "\n",
    "optimizer_params = {'lr': 1e-3, 'betas': (0.9, 0.999), 'eps': 1e-5, 'weight_decay': 0., 'amsgrad': True}\n",
    "\n",
    "hyperparameters = {'seed': seed,\n",
    "                   'batch_size': batch_size, 'max_repeats': max_repeats, 'sequence_length': sequence_length,\n",
    "                   'embedding_dim': embedding_dim, 'hidden_dim': hidden_dim, 'dropout': dropout,\n",
    "                   'n_epochs': n_epochs,\n",
    "                   'optimizer_params': optimizer_params}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "print()\n",
    "\n",
    "ud_dataset = UndertaleDeltaruneDataset(\"./source/converted_texts\", batch_size, max_repeats)\n",
    "ud_loader = UDBatchLoader(ud_dataset, batch_size, sequence_length, False, True)\n",
    "\n",
    "model = UDNet(len(ud_dataset.tokens), embedding_dim, hidden_dim, n_lstm_layers, dropout)\n",
    "model.to(device)\n",
    "\n",
    "optimizer              = optim.Adam(model.parameters(), **optimizer_params)\n",
    "criterion              = nn.CrossEntropyLoss()\n",
    "lr_scheduler           = None\n",
    "\n",
    "history = {}\n",
    "\n",
    "print()\n",
    "print('Data Sequence Total Length:', ud_dataset.data_len())\n",
    "print()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:01:28.903456Z",
     "start_time": "2019-03-23T02:53:34.832445Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "history = train(model, optimizer, criterion, n_epochs, device, ud_loader, lr_scheduler,\n",
    "                prehistory=history, checkpoint_dir='.', checkpoint_basename='PoC', save_every=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Best Model\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:13.507027Z",
     "start_time": "2019-03-23T08:02:13.477834Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_dict = torch.load(\"./PoC_best.pth\", map_location=device)\n",
    "history = loaded_dict['history']\n",
    "hyperparameters = loaded_dict['hyperparameters']\n",
    "model_dict = loaded_dict['model_dict']\n",
    "optimizer_dict = loaded_dict['optimizer_dict']\n",
    "lr_dict = loaded_dict['lr_dict']\n",
    "\n",
    "model.load_state_dict(model_dict)\n",
    "optimizer.load_state_dict(optimizer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T05:02:36.889228Z",
     "start_time": "2019-03-19T05:02:36.308984Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if True: # Plot the history of the loaded model\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(24, 12), facecolor=fig_bg_color)\n",
    "    axes[0].set_facecolor(plot_bg_color)\n",
    "    axes[0].grid(True)\n",
    "    axes[0].set_title(\"Training Loss\", fontsize=fontsize)\n",
    "    axes[0].set_xlabel(\"Epoch\", fontsize=fontsize)\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=fontsize)\n",
    "    axes[0].plot(history['epoch'], history['loss'], color='blue', label='loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].set_facecolor(plot_bg_color)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].set_title(\"Training Accuracy\", fontsize=fontsize)\n",
    "    axes[1].set_xlabel(\"Epoch\", fontsize=fontsize)\n",
    "    axes[1].set_ylabel(\"Accuracy\", fontsize=fontsize)\n",
    "    axes[1].plot(history['epoch'], history['acc_1'], color='blue', label='top-1 acc')\n",
    "    axes[1].plot(history['epoch'], history['acc_5'], color='orange', label='top-5 acc')\n",
    "    axes[1].legend()\n",
    "\n",
    "    xlim = axes[0].get_xlim()\n",
    "    xticks = [tick for tick in axes[0].get_xticks() if xlim[0] <= tick <= xlim[1]]\n",
    "    index = len(history['loss']) - 1 - history['loss'][::-1].index(max(history['loss']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    index = len(history['loss']) - 1 - history['loss'][::-1].index(min(history['loss']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    if history['epoch'][-1] not in xticks:\n",
    "        xticks.append(history['epoch'][-1])\n",
    "    axes[0].set_xticks(xticks)\n",
    "\n",
    "    xlim = axes[1].get_xlim()\n",
    "    xticks = [tick for tick in axes[1].get_xticks() if xlim[0] <= tick <= xlim[1]]\n",
    "    index = len(history['acc_1']) - 1 - history['acc_1'][::-1].index(max(history['acc_1']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    index = len(history['acc_1']) - 1 - history['acc_1'][::-1].index(min(history['acc_1']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    index = len(history['acc_5']) - 1 - history['acc_5'][::-1].index(max(history['acc_5']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    index = len(history['acc_5']) - 1 - history['acc_5'][::-1].index(min(history['acc_5']))\n",
    "    if index not in xticks:\n",
    "        xticks.append(index)\n",
    "    if history['epoch'][-1] not in xticks:\n",
    "        xticks.append(history['epoch'][-1])\n",
    "    axes[1].set_xticks(xticks)\n",
    "\n",
    "    ylim = axes[0].get_ylim()\n",
    "    yticks = [tick for tick in axes[0].get_yticks() if ylim[0] <= tick <= ylim[1]]\n",
    "    if max(history['loss']) not in yticks:\n",
    "        yticks.append(max(history['loss']))\n",
    "    if min(history['loss']) not in yticks:\n",
    "        yticks.append(min(history['loss']))\n",
    "    if history['loss'][-1] not in yticks:\n",
    "        yticks.append(history['loss'][-1])\n",
    "    axes[0].set_yticks(yticks)\n",
    "\n",
    "    ylim = axes[1].get_ylim()\n",
    "    yticks = [tick for tick in axes[1].get_yticks() if ylim[0] <= tick <= ylim[1]]\n",
    "    if max(history['acc_1']) not in yticks:\n",
    "        yticks.append(max(history['acc_1']))\n",
    "    if min(history['acc_1']) not in yticks:\n",
    "        yticks.append(min(history['acc_1']))\n",
    "    if history['acc_1'][-1] not in yticks:\n",
    "        yticks.append(history['acc_1'][-1])\n",
    "    axes[1].set_yticks(yticks);\n",
    "    ylim = axes[1].get_ylim()\n",
    "    yticks = [tick for tick in axes[1].get_yticks() if ylim[0] <= tick <= ylim[1]]\n",
    "    if max(history['acc_1']) not in yticks:\n",
    "        yticks.append(max(history['acc_1']))\n",
    "    if min(history['acc_1']) not in yticks:\n",
    "        yticks.append(min(history['acc_1']))\n",
    "    if history['acc_1'][-1] not in yticks:\n",
    "        yticks.append(history['acc_1'][-1])\n",
    "    if max(history['acc_5']) not in yticks:\n",
    "        yticks.append(max(history['acc_5']))\n",
    "    if min(history['acc_5']) not in yticks:\n",
    "        yticks.append(min(history['acc_5']))\n",
    "    if history['acc_5'][-1] not in yticks:\n",
    "        yticks.append(history['acc_5'][-1])\n",
    "    axes[1].set_yticks(yticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:25.417856Z",
     "start_time": "2019-03-23T08:02:25.411986Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(model, input, hidden_states, top_k=5, temperature=1., return_as_tensor=False):\n",
    "    assert top_k > 0\n",
    "    assert temperature >= 0\n",
    "    with torch.no_grad():\n",
    "        output, hidden_states = model(input.view(1, -1), hidden_states)\n",
    "        probs = output[0].softmax(dim=1)\n",
    "    \n",
    "    if temperature == 0 or top_k == 1:\n",
    "        sampled = probs[-1].argmax(dim=0, keepdim=True)\n",
    "    else:\n",
    "        top_k_probs, top_k_args = probs[-1].topk(k=top_k, dim=0)\n",
    "        top_idx = torch.multinomial(top_k_probs.pow(1 / temperature), 1)\n",
    "        sampled = top_k_args.gather(dim=0, index=top_idx)\n",
    "    \n",
    "    if return_as_tensor:\n",
    "        return sampled, hidden_states\n",
    "    return sampled.item(), hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation Function\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:26.321622Z",
     "start_time": "2019-03-23T08:02:26.310998Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(model, length, starting_tokens=[], starting_len=100, top_k=5, temperature=1.):\n",
    "    # `starting_len` is used to sample a sequence from ud_dataset when `staring_tokens` is not given.\n",
    "    if starting_tokens:\n",
    "        tokens = starting_tokens\n",
    "        note = torch.tensor(starting_tokens, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        tokens = ud_dataset[0][0][:starting_len].tolist()\n",
    "        note = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "    \n",
    "    hidden_states = model.init_hidden(1)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm.tqdm(range(length), desc='Generating Tokens:', unit='token')\n",
    "        for _ in iterator:\n",
    "            note, hidden_states = sample(model, note, hidden_states, top_k, temperature, True)\n",
    "            tokens.append(note.item())\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def predict(model, ud_dataset, device=device):\n",
    "    inputs, targets = ud_dataset[0]\n",
    "    original = inputs[:1].tolist() + targets.tolist()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    seq_len = 2000\n",
    "    \n",
    "    predicted = [inputs[:1].item()]\n",
    "    \n",
    "    hidden_states = model.init_hidden(1)\n",
    "    hidden_states = ([hidden.detach() for hidden in hidden_states[0]],\n",
    "                     [cell.detach() for cell in hidden_states[1]])\n",
    "    model.eval()\n",
    "    \n",
    "    iterable = zip(range(0, len(inputs), seq_len), range(seq_len, len(inputs) + seq_len - 1, seq_len))\n",
    "    progress = tqdm.tqdm(iterable, desc='Processing Dataset:', total=inputs.size(0), unit='token')\n",
    "    with torch.no_grad():\n",
    "        for start, end in iterable:\n",
    "            outputs, hidden_states = model(inputs.data[start:end].unsqueeze(0).to(device), hidden_states)\n",
    "            predicted.extend(outputs.data.squeeze(0).argmax(dim=1, keepdim=False).cpu().tolist())\n",
    "            if end <= inputs.size(0):\n",
    "                progress.update(seq_len)\n",
    "            else:\n",
    "                progress.update(inputs.size(0) - start)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return original, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Generation\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:27.373250Z",
     "start_time": "2019-03-23T08:02:27.365931Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokens_to_intlist(tokens, token_to_key_dict):\n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "\n",
    "    patterns = []\n",
    "    intlist = []\n",
    "    last_pattern = tuple()\n",
    "\n",
    "    for token in tokens:\n",
    "        pattern = token_to_key_dict[token]\n",
    "        if pattern != tuple() and pattern[0] == \"<REPEAT>\":\n",
    "            for _ in range(pattern[1]):\n",
    "                patterns.append(last_pattern)\n",
    "        else:\n",
    "            patterns.append(pattern)\n",
    "            last_pattern = pattern\n",
    "\n",
    "    intlist.extend(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        intlist.append(0)\n",
    "        intlist.extend(pattern)\n",
    "    \n",
    "    return intlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:28.128888Z",
     "start_time": "2019-03-23T08:02:28.125215Z"
    }
   },
   "outputs": [],
   "source": [
    "def intlist_to_text(intlist):\n",
    "    return \" \".join([str(int) for int in intlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:42.951153Z",
     "start_time": "2019-03-23T08:02:32.595797Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_tokens, predicted_tokens = predict(model, ud_dataset)\n",
    "original_intlist, predicted_intlist = tokens_to_intlist(original_tokens, ud_dataset.tokens), tokens_to_intlist(predicted_tokens, ud_dataset.tokens)\n",
    "original_text, predicted_text = intlist_to_text(original_intlist), intlist_to_text(predicted_intlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:02:47.148425Z",
     "start_time": "2019-03-23T08:02:47.135549Z"
    }
   },
   "outputs": [],
   "source": [
    "filebase = \"./poc\"\n",
    "\n",
    "with open(filebase + \"_orig.txt\", 'w') as f:\n",
    "    f.write(original_text)\n",
    "with open(filebase + \"_pred.txt\", 'w') as f:\n",
    "    f.write(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:04:49.273095Z",
     "start_time": "2019-03-23T08:03:26.344385Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_tokens = generate(model, 50000, starting_tokens=[], starting_len=1, top_k=5, temperature=1.)\n",
    "generated_intlist = tokens_to_intlist(generated_tokens, ud_dataset.tokens)\n",
    "generated_text = intlist_to_text(generated_intlist)\n",
    "\n",
    "print(\"Generated Tokens ({})\".format(len(generated_tokens)))\n",
    "print(generated_tokens[:100] + ['...'])\n",
    "print(\"\\nInt List ({})\".format(len(generated_intlist)))\n",
    "print(generated_intlist[:100] + ['...'])\n",
    "print(\"\\nText ({})\".format(len(generated_text)))\n",
    "print(generated_text[:500] + ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:04:57.468769Z",
     "start_time": "2019-03-23T08:04:57.462677Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = \"./poc_gen.txt\"\n",
    "\n",
    "with open(filepath, 'w') as f:\n",
    "    f.write(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary, Notes, and Thoughts\n",
    "[(go to top)](#Undertale-&-Deltarune-Soundtrack-Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
